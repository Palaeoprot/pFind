{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPYHs6a1kgMBk3gRjvgJgqM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Palaeoprot/pFind/blob/main/pFind_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pFind3 Routines\n",
        "[Github](https://github.com/pFindStudio/pFind3)\n",
        "\n",
        "\n",
        "Open-pFind enables precise, comprehensive and rapid peptide identification in shotgun proteomics Hao Chi, Chao Liu, Hao Yang, Wen-Feng Zeng, Long Wu, Wen-Jing Zhou, Xiu-Nan Niu, Yue-He Ding, Yao Zhang, Rui-Min Wang, Zhao-Wei Wang, Zhen-Lin Chen, Rui-Xiang Sun, Tao Liu, Guang-Ming Tan, Meng-Qiu Dong, Ping Xu, Pei-Heng Zhang, Si-Min He. BioRxiv, Mar. 20, 2018.\n"
      ],
      "metadata": {
        "id": "E9lx8h8tBurq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Analytical Scripts\n"
      ],
      "metadata": {
        "id": "lNSR-u5cC5f_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scripts are used for compare two or more identification results from pFind 3.\n",
        "\n",
        "Modified from\n",
        "[https://github.com/daheitu/scripts_for_pFind3_protocol.io](https://github.com/daheitu/scripts_for_pFind3_protocol.io)\n",
        "\n",
        "\n",
        "Create a new folder in a desired location and give it a name.\n",
        "\n",
        "To compare across samples either the identified proteins or PTMs, respectively, copy either\n",
        "###“pFind_protein_contrast_script.py”\n",
        "or\n",
        "###“pFind_PTM_contrast_script.py”\n",
        "\n",
        "and the different pFind.protein files to be compared into this new folder. Note that each pFind.protein file should be renamed before it comes to this folder.\n",
        "\n",
        "The file name should be a ready reminder of the sample and the purpose of the search.\n",
        "\n",
        "Open “pFind_protein_contrast_script.py” or “pFind_PTM_contrast_script.py” using ‘Notepad++’ or another editor, specify the path of the new folder and save.\n",
        "\n",
        "You may change the name of the output file if you dislike the default one.\n",
        "\n",
        "\n",
        "Header annotation of pFind_protein_contrast_result.txt and that of or pFind_PTM_contrast_result.txt can be found in Table S9 and Table S10 in SI."
      ],
      "metadata": {
        "id": "Malx9XS_5DX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collagen Sequences"
      ],
      "metadata": {
        "id": "o_VIjqGX5dR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### COL1A1\n",
        "* [Calf COL1A1 PO2453](https://www.uniprot.org/uniprotkb/P02453/entry) Bovine Collagen\n",
        "\n",
        "*QLSYGYDEKSTGISVP*GPMGPSGPRGLPGPPGAPGPQGFQGPPGEPGEPGASGPMGPRGPPGPPGKNGDDGEAGKPGRPGERGPPGPQGARGLPGTAGLPGMKGHRGFSGLDGAKGDAGPAGPKGEPGSPGENGAPGQMGPRGLPGERGRPGAPGPAGARGNDGATGAAGPPGPTGPAGPPGFPGAVGAKGEGGPQGPRGSEGPQGVRGEPGPPGPAGAAGPAGNPGADGQPGAKGANGAPGIAGAPGFPGARGPSGPQGPSGPPGPKGNSGEPGAPGSKGDTGAKGEPGPTGIQGPPGPAGEEGKRGARGEPGPAGLPGPPGERGGPGSRGFPGADGVAGPKGPAGERGAPGPAGPKGSPGEAGRPGEAGLPGAKGLTGSPGSPGPDGKTGPPGPAGQDGRPGPPGPPGARGQAGVMGFPGPKGAAGEPGKAGERGVPGPPGAVGPAGKDGEAGAQGPPGPAGPAGERGEQGPAGSPGFQGLPGPAGPPGEAGKPGEQGVPGDLGAPGPSGARGERGFPGERGVQGPPGPAGPRGANGAPGNDGAKGDAGAPGAPGSQGAPGLQGMPGERGAAGLPGPKGDRGDAGPKGADGAPGKDGVRGLTGPIGPPGPAGAPGDKGEAGPSGPAGPTGARGAPGDRGEPGPPGPAGFAGPPGADGQPGAKGEPGDAGAKGDAGPPGPAGPAGPPGPIGNVGAPGPKGARGSAGPPGATGFPGAAGRVGPPGPSGNAGPPGPPGPAGKEGSKGPRGETGPAGRPGEVGPPGPPGPAGEKGAPGADGPAGAPGTPGPQGIAGQRGVVGLPGQRGERGFPGLPGPSGEPGKQGPSGASGERGPPGPMGPPGLAGPPGESGREGAPGAEGSPGRDGSPGAKGDRGETGPAGPPGAPGAPGAPGPVGPAGKSGDRGETGPAGPAGPIGPVGARGPAGPQGPRGDKGETGEQGDRGIKGHRGFSGLQGPPGPPGSPGEQGPSGASGPAGPRGPPGSAGSPGKDGLNGLPGPIGPPGPRGRTGDAGPAGPPGPPGPPGPPGPP*SGGYDLSFLPQPPQEKAHDGGRYYRA*\n",
        "\n",
        "\n",
        "* [Chicken COL1A1 PENSGALT00010061538.1](https://www.ensembl.org/Gallus_gallus/Transcript/Summary?db=core;g=ENSGALG00010025092;r=27:2738241-2755487;t=ENSGALT00010061420)\n",
        "*QMSYGYDEKSAGVAVP*GPMGPAGPRGLPGPPGAPGPQGFQGPPGEPGEPGASGPMGPRGPAGPPGKNGDDGEAGKPGRPGQRGPPGPQGARGLPGTAGLPGMKGHRGFSGLDGAKGQPGPAGPKGEPGSPGENGAPGQMGPRGLPGERGRPGPSGPAGARGNDGAPGAAGPPGPTGPAGPPGFPGAAGAKGETGPQGARGSEGPQGARGEPGPPGPAGAAGPAGNPGADGQPGAKGATGAPGIAGAPGFPGARGPSGPQGPSGAPGPKGNSGEPGAPGNKGDTGAKGEPGPAGVQGPPGPAGEEGKRGARGEPGPAGLPGPAGERGAPGSRGFPGADGIAGPKGPPGERGSPGAVGPKGSPGEAGRPGEPGLPGAKGLTGSPGSPGPDGKTGPPGPAGQDGRPGPPGPPGARGQAGVMGFPGPKGAAGEPGKPGERGAPGPPGAVGAAGKDGEAGAQGPPGPTGPAGERGEQGPAGAPGFQGLPGPAGPPGEAGKPGEQGVPGDAGAPGPAGARGERGFPGERGVQGPPGPQGPRGANGAPGNDGAKGDAGAPGAPGNQGPPGLQGMPGERGAAGLPGAKGDRGDPGPKGADGAPGKDGLRGLTGPIGPPGPAGAPGDKGEAGPPGPAGPTGARGAPGDRGEPGPPGPAGFAGPPGADGQPGAKGETGDAGAKGDAGPPGPAGPTGAPGPAGAVGAPGPKGARGSAGPPGATGFPGAAGRVGPPGPSGNIGLPGPPGPSGKEGGKGPRGETGPAGRPGEPGPAGPPGPPGEKGSPGADGPIGAPGTPGPQGIAGQRGVVGLPGQRGERGFPGLPGPSGEPGKQGPSGSPGERGPPGPMGPPGLAGPPGEAGREGAPGAEGAPGRDGAAGPKGDRGETGPAGPPGAPGAPGAPGPVGPAGKNGDRGETGPAGPAGPPGPAGARGPAGPQGPRGDKGETGEQGDRGMKGHRGFSGLQGPPGPPGAPGEQGPSGASGPAGPRGPPGSAGAAGKDGLNGLPGPIGPPGPRGRTGEVGPVGPPGPPGPPGPPGPPSGGFDFSFLPQPPQEKAHDGGRYYRA\n",
        "\n",
        ">sp|P02457|CO1A1_CHICK\n",
        "\n",
        "QMSYGYDEKSAGVAVPGPMGPAGPRGLPGPPGAPGPQGFQGPPGEPGEPGASGPMGPRGPAGPPGKNGDDGEAGKPGRPGQRGPPGPQGARGLPGTAGLPGMKGHRGFSGLDGAKGQPGPAGPKGEPGSPGENGAPGQMGPRGLPGERGRPGPSGPAGARGNDGAPGAAGPPGPTGPAGPPGFPGAAGAKGETGPQGARGSEGPQGSRGEPGPPGPAGAAGPAGNPGADGQPGAKGATGAPGIAGAPGFPGARGPSGPQGPSGAPGPKGNSGEPGAPGNKGDTGAKGEPGPAGVQGPPGPAGEEGKRGARGEPGPAGLPGPAGERGAPGSRGFPGADGIAGPKGPPGERGSPGAVGPKGSPGEAGRPGEAGLPGAKGLTGSPGSPGPDGKTGPPGPAGQDGRPGPAGPPGARGQAGVMGFPGPKGAAGEPGKPGERGAPGPPGAVGAAGKDGEAGAQGPPGPTGPAGERGEQGPAGAPGFQGLPGPAGPPGEAGKPGEQGVPGNAGAPGPAGARGERGFPGERGVQGPPGPQGPRGANGAPGNDGAKGDAGAPGAPGNEGPPGLEGMPGERGAAGLPGAKGDRGDPGPKGADGAPGKDGLRGLTGPIGPPGPAGAPGDKGEAGPPGPAGPTGARGAPGDRGEPGPPGPAGFAGPPGADGQPGAKGETGDAGAKGDAGPPGPAGPTGAPGPAGZVGAPGPKGARGSAGPPGATGFPGAAGRVGPPGPSGNIGLPGPPGPAGKZGSKGPRGETGPAGRPGEPGPAGPPGPPGEKGSPGADGPIGAPGTPGPQGIAGQRGVVGLPGQRGERGFPGLPGPSGEPGKQGPSGASGERGPPGPMGPPGLAGPPGEAGREGAPGAEGAPGRDGAAGPKGDRGETGPAGPPGAPGAPGAPGPVGPAGKNGDRGETGPAGPAGPPGPAGARGPAGPQGPRGDKGETGEQGDRGMKGHRGFSGLQGPPGPPGAPGEQGPSGASGPAGPRGPPGSAGAAGKDGLNGLPGPIGPPGPRGRTGEVGPVGPPGPPGPPGPPGPPSGGFDLSFLPQPPQEKAHDGGRYYRA\n",
        "\n",
        "* [Quail Coturnix japonica COL1A1 A0A8C2U9L6](https://www.uniprot.org/uniprotkb/A0A8C2U9L6/entry)\n",
        "QMSYGYDEKSGGMAVPGPMVSGGLGVRVGFGGPQGFQGPPGEPGEPGASVSAGGEAGKPGRPGERGPPGPQGARGLPGTAGLPGMKGHRGFSGLDGAKGEPGPAGPKGEPGSPGENGAPGQMGPRGLPGERGRPGPSGPAVSIGDPGARPTPVPPPQGETGPQGARGSEGPQGARGEPGPPGPAGAAGPAGNPGADGQPGAKGATGAPGIAGAPGFPGARGPSGPQGPSGAPGPKGNSGEPGAPGNKGDTGAKGEPGPAGVQGPPGPAGEEGKRGARGEPGPAGLPGPAGERGAPGSRGFPGADGIAGPKGPPGERGAPGAVGPKGSPGEAGRPGEPGLPGAKGLTGSPGSPGPDGKTGPPGPAGQDGRPGPPGPPGARGQAGVMGFPGPKGAAGEPGKPGERGAPGPPGAVGAAGKDGEAGAQGPPGPTGPAGERGEQGPAGAPGFQGLPGPAGPPGEAGKPGEQGERGFPGERGVQGPPGPQGPRGANGAPGNDGAKGDAGAPGAPGNQGPPGLQGMPGERGAAGLPGAKGDR--------------------------------------APMWDAAPPDRSVSPLQGATGFPGAAGRVGPPGPSVSAEPPSRGGILPWHRGKGPRGETGPAGRPGEPGPAGPPGPPGEKGSPGADGPIGAPGTPGPQGIAGQRGVVGLPGQRGERGFPGLPGPSGEPGKQGPSGSPGERGPPGPMGPPGLAGPPGEAGREGAPGAEGAPGRDGAAGPKVSTQGWGDGVGPQGPRGDKGETGDRGDRGMKGHRGFSGLQGPPGPPGAPGEQGPSGASGPHRGDTRGTHSVGVPPVGEAGPVGPPGPPGPPGPPGPPSGGFDFSFLPQPPQEKAHDGGRYYRA\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[CO1A1 C0HJN3 Orycteropus afer (Aardvark)](https://www.uniprot.org/uniprotkb/C0HJN3/entry)\n",
        "\n",
        "----------------GPMGPSGPRGIPGPPGAPGPQGFQGPPGEPGEPGASGPMGPRGPPGPPGKNGDDGEAGKPGRPGERGPPGPQGARGIPGTAGIPGMKGHRGFSGIDGAKGDAGPAGPKGEPGSPGENGAPGQMGPRGIPGERGRPGPPGPAGARGNDGATGAAGPPGPTGPAGPPGFPGAVGAKGEAGPQGPRGSEGPQGVRGEPGPPGPAGAAGPAGNPGADGQPGAKGANGAPGIAGAPGFPGARGPSGPQGPSGAPGPKGNSGEPGAPGNKGDAGAKGEPGPAGIQGPPGPAGEEGKRGARGEPGPTGIPGPPGE------RGFPGSDGVAGPKGPVGERGSPGPAGPKGSPGEAGRPGEAGIPGAKGITGSPGSPGPDGKTGPPGPAGQDGRPGPPGPPGARGQAGVMGFPGPKGAAGEPGKAGERGVPGPPGAVGAPGKDGEAGAPGATGPAGPAGERGEQGPAGSPGFQGIPGPAGPPGESGKPGEQGIPGDIGAPGPSGARGERGFPGERGVQGPPGPAGPRGSNGAPGNDGAKGDAGAPGAPGSQGAPGIQGMPGERGAAGIPGPKGDRGDAGPKGADGSPGKDGPRGITGPIGPPGPAGAPGDKGESGPNGPAGPTGARGAPGDRGEPGPPGPAGFAGPPGADGQPGAKGEPGDAGAKGDAGPPGPAGPTGAPGPIGNVGAPGPKG---SPGPPGATGFPGAAGRVGPPGPSGNAGPPGPPGPAGK-------GETGPAGRPGEIGPPGPPGPSGEKGSPGADGPAGAPGTPGPQGIGGQRGVVGIPGQ---RGFPGIPGPSGEPGKQGPSGPNGERGPPGPMGPPGIAGPPGESGREGSPGAEGSPGRDGSPGPKGDRGETGPAGPPGAPGAPGAPGPVGPAGKSGDRGETGPAGPAGPIGPVGARGPTGPQGPRGDKGETGEQGD------RGFSGIQGPPGPPGSPGEQGPSGASGPAGPRGPPGSAGAPGKDGINGIPGPIGPPGPR--TGDAGPVGPPGPPGPPGPPGPP---------------------------\n",
        "\n",
        "[COLA1 C0HLI1 Doedicurus sp. (South American giant glyptodont)](https://www.uniprot.org/uniprotkb/C0HLI1/entry)\n",
        "\n",
        "------DEKSAGGISVPGPMGPSGPRGLPGPPGAPGPQGFQGPPGEPGEPGASGPMGPRGPPGPPGKNGDDGEAGKPGRPGERGPPGPQGARGLPGTAGLPGMKGHRGFSGLDGAKGDAGPAGPKGEPGSPGENGAPGQMGPRGLPGERGRPGASGPAGARGNDGATGAAGPPGPTGPAGPPGFPGAVGAKGEAGPQGARGSEGPQGVRGEPGPPGPAGAAGPAGNPGADGQPGAKGANGAPGIAGAPGFPGARGPSGPQGPSGAPGPKGNSGEPGAPGNKGDTGAKGEPGPTGIQGPPGPAGEEGKRGARGEPGPTGLPGPPGERGGPGSRGFPGADGIAGPKGPAGERGSPGPAGPKGSPGEAGRPGEAGLPGAKGLTGSPGSPGPDGKTGPPGPAGQDGRPGPAGPPGARGQAGVMGFPGPKGAAGEPGKAGERGVPGPPGAVGPAGKDGEAGAQGPPGPAGPAGERGEQGPAG-PGFQGLPGPAGPPGEAGKPGEQGVPGDLGAPGPSGARGERGFPGERGVQGPPGPAGPRG-NGAPGNDGAKGDAGAPGAPGSQGAPGLQGMPGERGAAGLPGPKGDRGDAGPKGADGAPGKDGVRGLTGPIGPPGPAGATGDKGEAGPSGPAGPTGARGAPGDRGEPGPPGPAGFAGPPGADGQPGAKGEPGDAGAKGDAGPSGPAGPTGPPGPIGNVGAPGPKGARGSAGPPGATGFPGAAGRVGPPGPSGNAGPPGPPGPVGKEGGKGPRGETGPAGRPGEVGPPGPPGPSGEKGSPGADGPAGAPGTPGPQGI-GQRGVVGLPGQRGERGFPGLPGPSGEPGKQGPSGSSGERGPPGPMGPPGLAGPPGEAGREGSPGAEGSPGRDGSPGPKGDRGETGP-GPPGAPGAPGAPGPVGPAGKSGDRGETGPSGPAGPAGPAGARGPAGPQGPRGDKGETGEQGDRGIKGHRGFSGLQGPAGPPGSPGEQGPSGASGPAGPRGPPGSAGTPGKDGLNGLPGPIGPPGPRGRTGDAGPVGPPGPPGPPGPPGPP--------------------------\n",
        "\n",
        ">sp|P02452|CO1A1_HUMAN\n",
        "\n",
        "QLSYGYDEKSTGGISVPGPMGPSGPRGLPGPPGAPGPQGFQGPPGEPGEPGASGPMGPRGPPGPPGKNGDDGEAGKPGRPGERGPPGPQGARGLPGTAGLPGMKGHRGFSGLDGAKGDAGPAGPKGEPGSPGENGAPGQMGPRGLPGERGRPGAPGPAGARGNDGATGAAGPPGPTGPAGPPGFPGAVGAKGEAGPQGPRGSEGPQGVRGEPGPPGPAGAAGPAGNPGADGQPGAKGANGAPGIAGAPGFPGARGPSGPQGPGGPPGPKGNSGEPGAPGSKGDTGAKGEPGPVGVQGPPGPAGEEGKRGARGEPGPTGLPGPPGERGGPGSRGFPGADGVAGPKGPAGERGSPGPAGPKGSPGEAGRPGEAGLPGAKGLTGSPGSPGPDGKTGPPGPAGQDGRPGPPGPPGARGQAGVMGFPGPKGAAGEPGKAGERGVPGPPGAVGPAGKDGEAGAQGPPGPAGPAGERGEQGPAGSPGFQGLPGPAGPPGEAGKPGEQGVPGDLGAPGPSGARGERGFPGERGVQGPPGPAGPRGANGAPGNDGAKGDAGAPGAPGSQGAPGLQGMPGERGAAGLPGPKGDRGDAGPKGADGSPGKDGVRGLTGPIGPPGPAGAPGDKGESGPSGPAGPTGARGAPGDRGEPGPPGPAGFAGPPGADGQPGAKGEPGDAGAKGDAGPPGPAGPAGPPGPIGNVGAPGAKGARGSAGPPGATGFPGAAGRVGPPGPSGNAGPPGPPGPAGKEGGKGPRGETGPAGRPGEVGPPGPPGPAGEKGSPGADGPAGAPGTPGPQGIAGQRGVVGLPGQRGERGFPGLPGPSGEPGKQGPSGASGERGPPGPMGPPGLAGPPGESGREGAPGAEGSPGRDGSPGAKGDRGETGPAGPPGAPGAPGAPGPVGPAGKSGDRGETGPAGPAGPVGPVGARGPAGPQGPRGDKGETGEQGDRGIKGHRGFSGLQGPPGPPGSPGEQGPSGASGPAGPRGPPGSAGAPGKDGLNGLPGPIGPPGPRGRTGDAGPVGPPGPPGPPGPPGPPSAGFDFSFLPQPPQEKAHDGGRYYRA\n",
        "\n",
        "\n",
        "[CO1A1 Q9XSJ7 Dog](https://www.uniprot.org/uniprotkb/Q9XSJ7/entry)\n",
        "\n",
        "QMSYGYDEKSTGGISVPGPMGPSGPRGLPGPPGAPGPQGFQGPPGEPGEPGASGPMGPRGPPGPPGKNGDDGEAGKPGRPGERGPPGPQGARGLPGTAGLPGMKGHRGFSGLDGAKGDAGPAGPKGEPGSPGENGAPGQMGPRGLPGERGRPGAPGPAGARGNDGATGAAGPPGPTGPAGPPGFPGAVGAKGEAGPQGARGSEGPQGVRGEPGPPGPAGAAGPAGNPGADGQPGAKGANGAPGIAGAPGFPGARGPSGPQGPSGPPGPKGNSGEPGAPGNKGDTGAKGEPGPTGIQGPPGPAGEEGKRGARGEPGPTGLPGPPGERGGPGSRGFPGADGVAGPKGPAGERGSPGPAGPKGSPGEAGRPGEAGLPGAKGLTGSPGSPGPDGKTGPPGPAGQDGRPGPPGPPGARGQAGVMGFPGPKGAAGEPGKAGERGVPGPPGAVGPAGKDGEAGAQGPPGPAGPAGERGEQGPAGSPGFQGLPGPAGPPGEAGKPGEQGVPGDLGAPGPSGARGERGFPGERGVQGPPGPAGPRGANGAPGNDGAKGDAGAPGAPGSQGAPGLQGMPGERGAAGLPGPKGDRGDAGPKGADGSPGKDGVRGLTGPIGPPGPAGAPGDKGEAGPSGPAGPTGARGAPGDRGEPGPPGPAGFAGPPGADGQPGAKGEPGDAGAKGDAGPPGPAGPTGPPGPIGNVGAPGPKGARGSAGPPGATGFPGAAGRVGPPGPSGNAGPPGPPGPAGKEGGKGARGETGPAGRPGEVGPPGPPGPAGEKGSPGADGPAGAPGTPGPQGIAGQRGVVGLPGQRGERGFPGLPGPSGEPGKQGPSGTSGERGPPGPMGPPGLAGPPGESGREGSPGAEGSPGRDGSPGPKGDRGETGPAGPPGAPGAPGAPGPVGPAGKNGDRGETGPAGPAGPIGPVGARGPAGPQGPRGDKGETGEQGDRGIKGHRGFSGLQGPPGPPGSPGEQGPSGASGPAGPRGPPGSAGSPGKDGLNGLPGPIGPPGPRGRTGDAGPVGPPGPPGPPGPPGPPSGGFDFSFLPQPPQEKAHDGGRYYRA\n",
        "\n",
        "\n",
        "[CO1A1 P0C2W8 Mammoth](https://www.uniprot.org/uniprotkb/P0C2W8/entry)\n",
        "\n",
        "QLSYGYDEKSAGGISVPGPMGPSGPRGLPGPPGAPGPQGFQGPPGEPGEPGASGPMGPRGPPGPPGKNGDDGEAGKPGRPGERGPPGPQGARGLPGTAGLPGMKGHRGFSGLDGAKGDAGPAGPKGEPGSPGENGAPGQMGPRGLPGERGRPGAPGPAGARGNDGATGAAGPPGPTGPAGPPGFPGAVGAKGEAGPQGARGSEGPQGVRGEPGPPGPAGAAGPAGNPGADGQPGAKGANGAPGIAGAPGFPGARGPAGPQGPSGAPGPKGNSGEPGAPGSKGDAGAKGEPGPIGIQGPPGPAGEEGKRGARGEPGPTGLPGPPGERGGPGSRGFPGADGVAGPKGPAGERGSPGPAGPKGSPGEAGRPGEAGLPGAKGLTGSPGSPGPDGKTGPPGPAGQDGRPGPPGPPGARGQAGVMGFPGPKGAAGEPGKAGERGVPGPPGAVGAAGKDGEAGAQGPPGPAGPAGERGEQGPAGSPGFQGLPGPAGPPGEAGKPGEQGVPGDLGAPGPSGARGERGFPGERGVQGPPGPAGPRGSNGAPGNDGAKGDAGAPGAPGSQGAPGLQGMPGERGAAGLPGPKGDRGDAGPKGADGSPGKDGPRGLTGPIGPPGPAGAPGDKGEAGPSGPAGPTGARGAPGDRGEPGPPGPAGFAGPPGADGQPGAKGEPGDAGAKGDAGPPGPAGPTGAPGPIGNVGAPGAKGARGSAGPPGATGFPGAAGRVGPPGPSGNAGPPGPPGPAGKEGGKGPRGETGPAGRPGEVGPPGPPGPAGEKGSPGADGPAGAPGTPGPQGIGGQRGVVGLPGQRGERGFPGLPGPSGEPGKQGPSGSSGERGPPGPAGPPGLAGPPGESGREGAPGAEGSPGRDGSPGPKGDRGETGPSGPPGAPGAPGAPGPVGPAGKSGDRGETGPAGPAGPAGPAGVRGPAGPQGPRGDKGETGEQGDRGLKGHRGFSGLQGPPGPPGSPGEQGPSGASGPAGPRGPPGSAGAPGKDGLNGLPGPPGPPGPRGRTGDAGPVGPPGPPGPPGPPGPPSGAFDFSFLPQPPQEKAHDGGRYYRA\n",
        "\n",
        "\n",
        "[CO1A1 C0HJN9 Horse](https://www.uniprot.org/uniprotkb/C0HJN9/entry)\n",
        "\n",
        "-----------------GPMGPSGPRGIPGPPGAPGPQGFQGPPGEPGEPGASGPMGPRGPPGPPGKNGDDGEAGKPGRPGERGPPGPQGARGIPGTAGIPGMK---GFSGIDGAKGDAGPAGPKGEPGSPGENGAPGQMGPRGIPGERGRPGAPGPAGARGNDGATGAAGPPGPTGPAGPPGFPGAVGAKGEAGPQGARGSEGPQGVRGEPGPPGPAGAAGPAGNPGADGQPGAKGANGAPGIAGAPGFPGARGPSGPQGPSGPPGPKGNSGEPGAPGNKGDTGAKGEPGPTGIQGPPGPAGEEGKR---GEPGPIGIPGPPG------ERGFPGADGVAGPKGPAGERGAPGPAGPKGSPGEAGRPGEAGIPGAKGITGSPGSPGPDGKTGPPGPAGQDGRPGPPGPPGARGQAGVMGFPGPKGAAGEPGK----GVPGPPGAVGPAGKDGEAGAQGPPGPAGPAGERGEQGPAGSPGFQGIPGPAGPPGESGKPGEQGVPGDIGAPGPSGA---RGFPGERGVQGPPGPAGPRS----------------------QGAPGIQGMPGERGAAGIPGPKGDRGDAGPK------------GITGPIGPPGPAGAPGDKGETGPSGPAGPTGAR-----RGEPGPPGPAGFAGPPGADGQPGAK---------GDAGPPGPAGPAGPPGPIGSVGAPGPK---GSAGPPGATGFPGAAGRVGPPGPSGNAGPPGPPGPVG----KGPRGETGPAGRPGEAGPPGPPGPAGEKGSPGADGPAGAPGTPGPQGIAGQRGVVGIPGQ---RGFPGIPGPSGEPGKQGPSGASGERGPPGPVGPPGIAGPPGESGREGSPGAEGSAGRDGSPGPKGDRGETGPAGPPGAPGAPGAPGPVGPAGKSGDRGEAGPAGPAGPIGPVGARGPAGPQGP------------------RGFSGIQGPPGPPGSPGEQGPSGASGPAGPRGPPGSAGAPGKDGINGIPGPIGPPGPR--------------------------------------------------\n",
        "\n",
        "\n",
        "[CO1A1 B9VR88 Donkey Equus asinus](https://www.uniprot.org/uniprotkb/B9VR88/entry)\n",
        "\n",
        "QLSYGYDEKSA-GISVPGPMGPSGPRGLPGPPGAPGPQGFQGPPGEPGEPGASGPMGPRGPPGPPGKNGDDGEAGKPGRPGERGPPGPQGARGLPGTAGLPGMKGHRGFSGLDGAKGDAGPAGPKGEPGSPGENGAPGQMGPRGLPGERGRPGAPGPAGARGNDGATGAAGPPGPTGPAGPPGFPGAVGAKGEAGPQGARGSEGPQGVRGEPGPPGPAGAAGPAGNPGADGQPGAKGANGAPGIAGAPGFPGARGPSGPQGPSGPPGPKGNSGEPGAPGNKGDTGAKGEPGPTGIQGPPGPAGEEGKRGARGEPGPTGLPGPPGERGGPGARGFPGADGVAGPKGPAGERGAPGPAGPKGSPGEAGRPGEAGLPGAKGLTGSPGSPGPDGKTGPPGPAGQDGRPGPPGPPGARGQAGVMGFPGPKGAAGEPGKAGERGVPGPPGAVGPAGKDGEAGAQGPPGPAGPAGERGEQGPAGSPGFQGLPGPAGPPGESGKPGEQGVPGDLGAPGPSGARGERGFPGERGVQGPPGPAGPRGSNGAPGNDGAKGDAGAPGAPGSQGAPGLQGMPGERGAAGLPGPKGDRGDAGPKGADGSPGKDGVRGLTGPIGPPGPAGAPGDKGETGPSGPAGPTGARGAPGDRGEPGPPGPAGFAGPPGADGQPGAKGEPGDAGAKGDAGPPGPAGPAGPPGPIGSVGAPGPKGARGSAGPPGATGFPGAAGRVGPPGPSGNAGPPGPPGPVGKEGGKGPRGETGPAGRPGEAGPPGPPGPAGEKGSPGADGPAGAPGTPGPQGIAGQRGVVGLPGQRGERGFPGLPGPSGEPGKQGPSGASGERGPPGPVGPPGLAGPPGESGREGSPGAEGSPGRDGSPGPKGDRGETGPAGPPGAPGAPGAPGPVGPAGKSGDRGEAGPAGPAGPIGPVGARGPAGPQGPRGDKGETGEQGDRGIKGHRGFSGLQGPPGPPGSPGEQGPSGASGPAGPRGPPGSAGAPGKDGLNGLPGPIGPPGPRGRTGDAGPVGPPGPPGPPGPPGPPSAGFDFSFLPQPPQEKSHDGGRYYRA\n",
        "\n",
        "\n",
        "[CO1A1 C0HJN7 CO1A1_TAPTE  Tapirus terrestris (Lowland tapir) (Brazilian tapir)](https://www.uniprot.org/uniprotkb/C0HJN7/entry)\n",
        "\n",
        "-----------------GPMGPSGPRGIPGPPGAPGPQGFA-----------SGPMGPRGPPGPPGKNGDDGEAGKPGRPGERGPPGPQGARGIPGTAGIPGMKGHRGFSGIDGAKGDAGPAGPKGEPGSPGENGAPGQMGPRGIPGERGRPGAPGPAGARGNDGATGAAGPPGPTGPAGPPGFPGAVGAKGEAGPQGARGSEGPQGVRGEPGPPGPAGAAGPAGNPGADGQPGAKGANGAPGIAGAPGFPGARGPSGPQGPSGPPGPKGNSGEPGAPGSKGDTGAKGEPGPTGIQGPPGPAGEEGKRGARGEPGPTGIPGPPGERGGPGARGFPGSDGVAGPKGPAGERGAPGPAGPKGSPGEAGRPGEAGIPGAKGITGSPGSPGPDGKTGPPGPAGQDGRPGPPGPPGARGQAGVMGFPGPKGAAGEPGKAGERGVPGPPGAVGPAGKDGEAGAQGPPGPAGPAGERGEQGPAGSPG-------------------------IGAPGPSGARGERGFPGERGVQGPPGPAGPRGANGAPGNDGA---------------KGIQGMPGERGAAGIPGPKGDRGDAGPKGADGSPGKDGVRGITGPIGPPGPAGAPGDKGESGPSGPAGPTGARGAPGDRGEPGPPGPAGFAGPPGADGQPGAKGEPGDAGAKGDAGPPGPAGPTGPPGPIGNVGAPGPKGARGSAGPPGATGFPGAAGRVGPPGPSGNAGPPGPPGPVGKEGGKGPRGETGPAGRPGEAGPPGPPGPAGEKGSPGADGPAGAPGTPGPQGIAGQRGVVGIPGQRGERGFPGIPGPSGEPGKQGPSGASGERGPPGPVGPPGIAGPPGESGREGAPGAEGSPGRDGSPGPKGDRGETGPAGPPGAPGAPGAPGPVGPAGKSGDRGETGPAGPAGPIGPVGARGPAGPQGPRGDKGETGEQGDRGIKGHRGFSGIQGPPGPPGSPGEQGPSGASGPAGPRGPPGSAGAPGKDGINGIPGPIGPPGPRGRTGDAGPVGPPGPPGPPGPPGPP--------------------------\n",
        "\n",
        "\n",
        "[CO1A1 C0HJN5 Hippopotamus amphibius (Hippopotamus)](https://www.uniprot.org/uniprotkb/C0HJN5/entry)\n",
        "\n",
        "-----------------GPMGPSGPRGIPGPPGAPGPQGFP------GEPGASGPMGPRGPPGPPGKNGDDGEAGKPGRPGERGPSGPQGARGIPGTAGIPGMKGHRGFSGIDGAKGDAGPAGPKG---------APGQMGPRGIPGERGRPGAPGPAGARGNDGATGAAGPPGPTGPAGPPGFPGAVGAKGEAGPQGARGSEGPQGVRGEPGPPGPAGAA---------------GANGAPGIAGAPGFPGARGPSGPQGPSGPSGPKGNSGEPGAPGSKGDTGAKGEPGPTGIQGPPGPAGEEGKRGARGEPGPAGIPGPPGERGGPGSRGFPGADGVAGPKGPAGERGSPGPAGPKGSPGEAGRPGEAGIPGAKGITGSPGSPGPDGKTGPPGPAGQDGRPGPPGPPGARGQAGVMGFPGPKGAAGEPGKAGERGVPGPPGAVGPAGKDGEAGAQGPPGPAGPAGERGEQGPAGSPGFQGIPGPAGPPGEAGKPGEQGVPGDIGAPGPSGARGERGFPGERGVQGPPGPAGPRGANGAPGNDGAKGDAGAPGAPGSQGAPGIQGMPGERGAAGIPGPKGDRGDAGPKGADGSPGKDGVRGITGPIGPPGPAGAPGDKGEAGPSGPAGPTGARGAPGDRGEPGPPGPAGFAGPPGADGQPGAKGEPGDAGAKG----------TGPPGPIGNVGAPGPKGARGSAGPPGATGFPGAAGRVGPPGPSGNAGPPGPPGPVGK------RGETGPAGRPGEVGPPGPPGPAGEKGAPGADGPAGAPGTPGPQGIAGQRGVVGIPGQRGERGFPGIPGPSGEPGKQGPSGTSGERGPPGPMGPPGIAGPPGESGREGAPGAEGSPGRDGSPGAKGDRGETGPAGPPGAPGAPGAPGPVGPAGKSGDRGETGPAGPAGPIGPVGARGAAGPQGPRGDKGETGEQGDRGIKGHRGFSGIQGPPGPPGSPGEQGPSGASGPAGPRGPPGSAGSPGKDGINGIPGPIGPPGPRP-----------GPPGPPGPPGPP--------------------------\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TqC4wMmF42hM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### COL1A2\n",
        "* [Calf COL1A2 P02465](https://www.uniprot.org/uniprotkb/P02465/entry)\n",
        "\n",
        "QFDAKGGGPGPMGLMGPRGPPGASGAPGPQGFQGPPGEPGEPGQTGPAGARGPPGPPGKAGEDGHPGKPGRPGERGVVGPQGARGFPGTPGLPGFKGIRGHNGLDGLKGQPGAPGVKGEPGAPGENGTPGQTGARGLPGERGRVGAPGPAGARGSDGSVGPVGPAGPIGSAGPPGFPGAPGPKGELGPVGNPGPAGPAGPRGEVGLPGLSGPVGPPGNPGANGLPGAKGAAGLPGVAGAPGLPGPRGIPGPVGAAGATGARGLVGEPGPAGSKGESGNKGEPGAVGQPGPPGPSGEEGKRGSTGEIGPAGPPGPPGLRGNPGSRGLPGADGRAGVMGPAGSRGATGPAGVRGPNGDSGRPGEPGLMGPRGFPGSPGNIGPAGKEGPVGLPGIDGRPGPIGPAGARGEPGNIGFPGPKGPSGDPGKAGEKGHAGLAGARGAPGPDGNNGAQGPPGLQGVQGGKGEQGPAGPPGFQGLPGPAGTAGEAGKPGERGIPGEFGLPGPAGARGERGPPGESGAAGPTGPIGSRGPSGPPGPDGNKGEPGVVGAPGTAGPSGPSGLPGERGAAGIPGGKGEKGETGLRGDIGSPGRDGARGAPGAIGAPGPAGANGDRGEAGPAGPAGPAGPRGSPGERGEVGPAGPNGFAGPAGAAGQPGAKGERGTKGPKGENGPVGPTGPVGAAGPSGPNGPPGPAGSRGDGGPPGATGFPGAAGRTGPPGPSGISGPPGPPGPAGKEGLRGPRGDQGPVGRSGETGASGPPGFVGEKGPSGEPGTAGPPGTPGPQGLLGAPGFLGLPGSRGERGLPGVAGSVGEPGPLGIAGPPGARGPPGNVGNPGVNGAPGEAGRDGNPGNDGPPGRDGQPGHKGERGYPGNAGPVGAAGAPGPQGPVGPVGKHGNRGEPGPAGAVGPAGAVGPRGPSGPQGIRGDKGEPGDKGPRGLPGLKGHNGLQGLPGLAGHHGDQGAPGAVGPAGPRGPAGPSGPAGKDGRIGQPGAVGPAGIRGSQGSQGPAGPPGPPGPPGPPGPSGGGYEFGFDGDFYRA\n",
        "\n",
        "\n",
        "* [Sheep W5NTT7](https://www.uniprot.org/uniprotkb/W5NTT7/entry)\n",
        "* [Goat COL1A2 ](https://www.ensembl.org/Capra_hircus/Transcript/Sequence_Protein?db=core;g=ENSCHIG00000025647;r=4:108820558-108856519;t=ENSCHIT00000039063)\n",
        "GLMGPRGPPGASGAPGPQGFQGPPGEPGEPGQTGARGLPGERGRVGAPGPAGAR\n",
        "GSDGSVGPVGPAGPIGSAGPPGFPGAPGPKGELGPVGNPGPAGPAGPRGEVGLPGLSGPV\n",
        "GPPGNPGANGLPGAKGAAGLPGVAGAPGLPGPRGIPGPVGAAGATGARGLVVSGRVLLYL\n",
        "MEEFSLIFFCVLCALFQGNPGSRGLPGADGRAGVMGPAGSRGATGPAGVRGPNGDSGRPG\n",
        "EPGLMGPRGFPGSPGNIGPAGKEGPAGLPGIDGRPGPIGPAGARGEPGNIGFPGPKGPTV\n",
        "RITTTSSPSALFCITIHQNSHFSLASGPSTSRGPLQHKKTGERGPPGESGAAGPTGPIGS\n",
        "RGPSGPPGPDGNKGEPGVVGAPGTAGPSGPSGLPGERGAAGIPGGKGEKVRSPHWALTHT\n",
        "GEAGPAGPAGPAGPRGSPGERGEVGPAGPNGFAGPAGAAGQPGAKGERGTKGPKGENGPV\n",
        "GPTGPVGAAGPSGPNGPPGPAGSRGDGGPPVSTYPGFGISGPPGPPGPAGKEGLRGPRGD\n",
        "QGPVGRTGEPGAAGPPGFVGEKGPSGEPGTAGPPGTPGPQGFLGPPGFLGLPGSRGERGL\n",
        "PGRVLYWALGVMTAGSPTVRGRWATVSLSGNPGNDGPPGRDGQPGHKGERGYPGNAGPVG\n",
        "AAGAPGPQGPVGPTGKHGSRGEPGPVGAVGPAGAVGPRGPSGPQGIRGDKGEPGDKGPRG\n",
        "LPGLKGHNGLQGLPGLAGHHGDQGAPGAVGPAGPRGPAGPTGPAGKDGRTGQPGAVGPAG\n",
        "IRGSQGSQGPAGPPGPPGPPGPPGPS\n",
        "\n",
        "\n",
        "* [Chicken COL1A2](https://www.uniprot.org/uniprotkb/P02467/entry#ptm_processing)\n",
        "QYDPSKAADFGPGPMGLMGPRGPPGASGPPGPPGFQGVPGEPGEPGQTGPQGPRGPPGPPGKAGEDGHPGKPGRPGERGVAGPQGARGFPGTPGLPGFKGIRGHNGLDGQKGQPGTPGTKGEPGAPGENGTPGQPGARGLPGERGRIGAPGPAGARGSDGSAGPTGPAGPIGAAGPPGFPGAPGAKGEIGPAGNVGPTGPAGPRGEIGLPGSSGPVGPPGNPGANGLPGAKGAAGLPGVAGAPGLPGPRGIPGPPGPAGPSGARGLVGEPGPAGAKGESGNKGEPGAAGPPGPPGPSGEEGKRGSNGEPGSAGPPGPAGLRGVPGSRGLPGADGRAGVMGPAGNRGASGPVGAKGPNGDAGRPGEPGLMGPRGLPGQPGSPGPAGKEGPVGFPGADGRVGPIGPAGNRGEPGNIGFPGPKGPTGEPGKPGEKGNVGLAGPRGAPGPEGNNGAQGPPGVTGNQGAKGETGPAGPPGFQGLPGPSGPAGEAGKPGERGLHGEFGVPGPAGPRGERGLPGESGAVGPAGPIGSRGPSGPPGPDGNKGEPGNVGPAGAPGPAGPGGIPGERGVAGVPGGKGEKGAPGLRGDTGATGRDGARGLPGAIGAPGPAGGAGDRGEGGPAGPAGPAGARGIPGERGEPGPVGPSGFAGPPGAAGQPGAKGERGPKGPKGETGPTGAIGPIGASGPPGPVGAAGPAGPRGDAGPPGMTGFPGAAGRVGPPGPAGITGPPGPPGPAGKDGPRGLRGDVGPVGRTGEQGIAGPPGFAGEKGPSGEAGAAGPPGTPGPQGILGAPGILGLPGSRGERGLPGIAGATGEPGPLGVSGPPGARGPSGPVGSPGPNGAPGEAGRDGNPGNDGPPGRDGAPGFKGERGAPGNPGPSGALGAPGPHGQVGPSGKPGNRGDPGPVGPVGPAGAFGPRGLAGPQGPRGEKGEPGDKGHRGLPGLKGHNGLQGLPGLAGQHGDQGPPGNNGPAGPRGPPGPSGPPGKDGRNGLPGPIGPAGVRGSHGSQGPAGPPGPPGPPGPPGPNGGGYEVGFDAEYYR\n",
        "\n",
        "\n",
        ">sp|P02465|CO1A2_BOVIN\n",
        "\n",
        "QFDAKGGGPGPMGLMGPRGPPGASGAPGPQGFQGPPGEPGEPGQTGPAGARGPPGPPGKAGEDGHPGKPGRPGERGVVGPQGARGFPGTPGLPGFKGIRGHNGLDGLKGQPGAPGVKGEPGAPGENGTPGQTGARGLPGERGRVGAPGPAGARGSDGSVGPVGPAGPIGSAGPPGFPGAPGPKGELGPVGNPGPAGPAGPRGEVGLPGLSGPVGPPGNPGANGLPGAKGAAGLPGVAGAPGLPGPRGIPGPVGAAGATGARGLVGEPGPAGSKGESGNKGEPGAVGQPGPPGPSGEEGKRGSTGEIGPAGPPGPPGLRGNPGSRGLPGADGRAGVMGPAGSRGATGPAGVRGPNGDSGRPGEPGLMGPRGFPGSPGNIGPAGKEGPVGLPGIDGRPGPIGPAGARGEPGNIGFPGPKGPSGDPGKAGEKGHAGLAGARGAPGPDGNNGAQGPPGLQGVQGGKGEQGPAGPPGFQGLPGPAGTAGEAGKPGERGIPGEFGLPGPAGARGERGPPGESGAAGPTGPIGSRGPSGPPGPDGNKGEPGVVGAPGTAGPSGPSGLPGERGAAGIPGGKGEKGETGLRGDIGSPGRDGARGAPGAIGAPGPAGANGDRGEAGPAGPAGPAGPRGSPGERGEVGPAGPNGFAGPAGAAGQPGAKGERGTKGPKGENGPVGPTGPVGAAGPSGPNGPPGPAGSRGDGGPPGATGFPGAAGRTGPPGPSGISGPPGPPGPAGKEGLRGPRGDQGPVGRSGETGASGPPGFVGEKGPSGEPGTAGPPGTPGPQGLLGAPGFLGLPGSRGERGLPGVAGSVGEPGPLGIAGPPGARGPPGNVGNPGVNGAPGEAGRDGNPGNDGPPGRDGQPGHKGERGYPGNAGPVGAAGAPGPQGPVGPVGKHGNRGEPGPAGAVGPAGAVGPRGPSGPQGIRGDKGEPGDKGPRGLPGLKGHNGLQGLPGLAGHHGDQGAPGAVGPAGPRGPAGPSGPAGKDGRIGQPGAVGPAGIRGSQGSQGPAGPPGPPGPPGPPGPSGGGYEFGFDGDFYRA\n",
        "\n",
        ">sp|P02467|CO1A2_CHICK\n",
        "\n",
        "QYDPSKAADFGPGPMGLMGPRGPPGASGPPGPPGFQGVPGEPGEPGQTGPQGPRGPPGPPGKAGEDGHPGKPGRPGERGVAGPQGARGFPGTPGLPGFKGIRGHNGLDGQKGQPGTPGTKGEPGAPGENGTPGQPGARGLPGERGRIGAPGPAGARGSDGSAGPTGPAGPIGAAGPPGFPGAPGAKGEIGPAGNVGPTGPAGPRGEIGLPGSSGPVGPPGNPGANGLPGAKGAAGLPGVAGAPGLPGPRGIPGPPGPAGPSGARGLVGEPGPAGAKGESGNKGEPGAAGPPGPPGPSGEEGKRGSNGEPGSAGPPGPAGLRGVPGSRGLPGADGRAGVMGPAGNRGASGPVGAKGPNGDAGRPGEPGLMGPRGLPGQPGSPGPAGKEGPVGFPGADGRVGPIGPAGNRGEPGNIGFPGPKGPTGEPGKPGEKGNVGLAGPRGAPGPEGNNGAQGPPGVTGNQGAKGETGPAGPPGFQGLPGPSGPAGEAGKPGERGLHGEFGVPGPAGPRGERGLPGESGAVGPAGPIGSRGPSGPPGPDGNKGEPGNVGPAGAPGPAGPGGIPGERGVAGVPGGKGEKGAPGLRGDTGATGRDGARGLPGAIGAPGPAGGAGDRGEGGPAGPAGPAGARGIPGERGEPGPVGPSGFAGPPGAAGQPGAKGERGPKGPKGETGPTGAIGPIGASGPPGPVGAAGPAGPRGDAGPPGMTGFPGAAGRVGPPGPAGITGPPGPPGPAGKDGPRGLRGDVGPVGRTGEQGIAGPPGFAGEKGPSGEAGAAGPPGTPGPQGILGAPGILGLPGSRGERGLPGIAGATGEPGPLGVSGPPGARGPSGPVGSPGPNGAPGEAGRDGNPGNDGPPGRDGAPGFKGERGAPGNPGPSGALGAPGPHGQVGPSGKPGNRGDPGPVGPVGPAGAFGPRGLAGPQGPRGEKGEPGDKGHRGLPGLKGHNGLQGLPGLAGQHGDQGPPGNNGPAGPRGPPGPSGPPGKDGRNGLPGPIGPAGVRGSHGSQGPAGPPGPPGPPGPPGPNGGGYEVGFDAEYYRA\n",
        "\n",
        ">tr|A0A5H1ZRJ7|A0A5H1ZRJ7_CHICK\n",
        "\n",
        "QYDPSKAADFGPGPMGLMGPRGPPGASGPPGPPGFQGVPGEPGEPGQTGPQGPRGPPGPPGKAGEDGHPGKPGRPGERGVAGPQGARGFPGTPGLPGFKGIRGHNGLDGQKGQPGTPGTKGEPGAPGENGTPGQPGARGLPGERGRIGAPGPAGARGSDGSAGPTGPAGPIGAAGPPGFPGAPGAKGEIGPAGNVGPTGPAGPRGEIGLPGSSGPVGPPGNPGANGLPGAKGAAGLPGVAGAPGLPGPRGIPGPPGPAGPSGARGLVGEPGPAGAKGESGNKGEPGAAGPPGPPGPSGEEGKRGSNGEPGSAGPPGPAGLRGVPGSRGLPGADGRAGVMGPAGNRGASGPVGAKGPNGDAGRPGEPGLMGPRGLPGQPGSPGPAGKEGPVGFPGADGRVGPIGPAGNRGEPGNIGFPGPKGPTGEPGKPGEKGNVGLAGPRGAPGPEGNNGAQGPPGVTGNQGAKGETGPAGPPGFQGLPGPSGPAGEAGKPGERGLHGEFGVPGPAGPRGERGLPGESGAVGPAGPIGSRGPSGPPGPDGNKGEPGNVGPAGAPGPAGPGGIPGERGVAGVPGGKGEKGAPGLRGDTGATGRDGARGLPGAIGAPGPAGGAGDRGEGGPAGPAGPAGARGIPGERGEPGPVGPSGFAGPPGAAGQPGAKGERGPKGPKGETGPTGAIGPIGASGPPGPVGAAGPAGPRGDAGPPGMTGFPGAAGRVGPPGPAGITGPPGPPGPAGKDGPRGLRGDVGPVGRTGEQGIAGPPGFAGEKGPSGEAGAAGPPGTPGPQGILGAPGILGLPGSRGERGLPGIAGATGEPGPLGVSGPPGARGPSGPVGSPGPNGAPGEAGRDGNPGNDGPPGRDGAPGFKGERGAPGNPGPSGALGAPGPHGQVGPSGKPGNRGDPGPVGPVGPAGAFGPRGLAGPQGPRGEKGEPGDKGHRGLPGLKGHNGLQGLPGLAGQHGDQGPPGNNGPAGPRGPPGPSGPPGKDGRNGLPGPIGPAGVRGSHGSQGPAGPPGPPGPPGPPGPNGGGYEVGFDAEYYRA"
      ],
      "metadata": {
        "id": "ZCIXLd8Hz4X2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### COL3A1\n",
        "\n",
        "* [Sheep COL3A1 W5Q4S0](https://www.uniprot.org/uniprotkb/W5Q4S0/entry)\n",
        "* [Calf COL3A1 P04258](https://www.uniprot.org/uniprotkb/P04258/entry)\n",
        "\n",
        "QYEAYDVKSGVAGGGIAGYPGPAGPPG\n",
        "PPGPPGTSGHPGAPGAPGYQGPPGEPGQAGPAGPPGPPGAIGPSGPAGKDGESGRPGRPG\n",
        "ERGFPGPPGMKGPAGMPGFPGMKGHRGFDGRNGEKGETGAPGLKGENGVPGENGAPGPMG\n",
        "PRGAPGERGRPGLPGAAGARGNDGARGSDGQPGPPGPPGTAGFPGSPGAKGEVGPAGSPG\n",
        "SSGAPGQRGEPGPQGHAGAPGPPGPPGSNGSPGGKGEMGPAGIPGAPGLIGARGPPGPPG\n",
        "TNGVPGQRGAAGEPGKNGAKGDPGPRGERGEAGSPGIAGPKGEDGKDGSPGEPGANGLPG\n",
        "AAGERGVPGFRGPAGANGLPGEKGPPGDRGGPGPAGPRGVAGEPGRDGLPGGPGLRGIPG\n",
        "SPGGPGSDGKPGPPGSQGETGRPGPPGSPGPRGQPGVMGFPGPKGNDGAPGKNGERGGPG\n",
        "GPGPQGPAGKNGETGPQGPPGPTGPSGDKGDTGPPGPQGLQGLPGTSGPPGENGKPGEPG\n",
        "PKGEAGAPGIPGGKGDSGAPGERGPPGAGGPPGPRGGAGPPGPEGGKGAAGPPGPPGSAG\n",
        "TPGLQGMPGERGGPGGPGPKGDKGEPGSSGVDGAPGKDGPRGPTGPIGPPGPAGQPGDKG\n",
        "ESGAPGVPGIAGPRGGPGERGEQGPPGPAGFPGAPGQNGEPGAKGERGAPGEKGEGGPPG\n",
        "AAGPAGGSGPAGPPGPQGVKGERGSPGGPGAAGFPGGRGPPGPPGSNGNPGPPGSSGAPG\n",
        "KDGPPGPPGSNGAPGSPGISGPKGDSGPPGERGAPGPQGPPGAPGPLGIAGLTGARGLAG\n",
        "PPGMPGARGSPGPQGIKGENGKPGPSGQNGERGPPGPQGLPGLAGTAGEPGRDGNPGSDG\n",
        "LPGRDGAPGAKGDRGENGSPGAPGAPGHPGPPGPVGPAGKSGDRGETGPAGPSGAPGPAG\n",
        "SRGPPGPQGPRGDKGETGERGAMGIKGHRGFPGNPGAPGSPGPAGHQGAVGSPGPAGPRG\n",
        "PVGPSGPPGKDGASGHPGPIGPPGPRGNRGERGSEGSPGHPGQPGPPGPPGAPGPCCGAG\n",
        "GVAAIAGVGAEKAGGFAPYY\n",
        "\n",
        "\n",
        "* [Goat COL3A1 XM_005675869](https://www.ncbi.nlm.nih.gov/nucleotide/XM_005675869.3?report=genbank&log$=nuclalign&blast_rank=1&RID=WA5BB2HB016)\n",
        "\n",
        "*[Chicken COL3A1](https://www.uniprot.org/uniprotkb/A0A1D5PE57/entry)\n",
        "\n",
        "  QYDSYDVKAGSVGMGYPPQPISGFPGPPGPSGPPGPPGHAGPPGSNGYQGPPGEPGQPGPSGPPGPAGMIGPAGPPGKDGEPGRPGRNGDRGIPGLPGHKGHPGMPGMPGMKGARGFDGKDGAKGDSGAPGPKGEAGQPGANGSPGQPGPGGPTGERGRPGNPGGPGAHGKDGAPGTAGPLGPPGPPGTAGFPGSPGFKGEAGPPGPAGASGNPGERGEPGPQGQAGPPGPQGPPGRAGSPGGKGEMGPSGIPGGPGPPGGRGLPGPPGTSGNPGAKGTPGEPGKNGAKGDPGPKGERGENGTPGARGPPGEEGKRGANGEPGQNGVPGTPGERGSPGFRGLPGSNGLPGEKGPAGERGSPGPPGPSGPAGDRGQDGGPGLPGMRGLPGIPGSPGSDGKPGPPGNQGEPGRSGPPGPAGPRGQPGVMGFPGPKGNEGAPGKNGERGPGGPPGTPGPAGKNGDVGLPGPPGPAGPAGDRGEPGPSGSPGLQGLPGGPGPAGENGKPGEPGPKGDIGGPGFPGPKGENGIPGERGPQGPPGPTGARGGPGPAGSEGAKGPPGPPGAPGGTGLPGLQGMPGERGASGSPGPKGDKGEPGGKGADGLPGARGERGNVGPIGPPGPAGPPGDKGETGPAGAPGPAGSRGGPGERGEQGLPGPAGFPGAPGQNGEPGGKGERGPPGLRGEAGPPGAAGPQGGPGAPGPPGPQGVKGERGSPGGPGAAGFPGARGPPGPPGNNGDRGESGPPGVPGPPGHPGPAGNNGAPGKAGERGFQGPLGPQGAIGSPGASGARGPPGPAGPPGKDGRGGYPGPIGPPGPRGNRGESGPAGPPGQPGLPGPSGPPGPCCGGGVASLGAGEKGPVGYGYEYR\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IC_ziVBw0AvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global Varibles"
      ],
      "metadata": {
        "id": "taooEB7d0GxA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Packages"
      ],
      "metadata": {
        "id": "R1Ec3Q5d0nzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data manipulation:\n",
        "import pandas as pd\n",
        "from itertools import islice\n",
        "#import sketch\n",
        "from collections import Counter\n",
        "\n",
        "# Debugging:\n",
        "import traceback\n",
        "\n",
        "# File I/O and path handling:\n",
        "import os\n",
        "import copy, os\n",
        "import re\n",
        "import requests\n",
        "import json\n",
        "from typing import Dict, Any\n",
        "\n",
        "\n",
        "# Numerical analysis and statistics:\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from statistics import mode, multimode  # Consider removing if unused\n",
        "\n",
        "# Data visualization:\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import to_rgba\n",
        "\n",
        "# Third-party modules (Commented out modules can be imported as needed):\n",
        "# from Bio import SeqIO  # Only import if used\n",
        "# from icecream import ic  # Import on demand if needed\n",
        "\n",
        "# Google Colab specific for mounting Google Drive:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "GiAz-Tf_OGox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequences"
      ],
      "metadata": {
        "id": "wYc8zjTK0v1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collagen_sequences = {\n",
        "    'Bov_COL1A1': {'offset': -7, 'sequence': 'STGISVPGPMGPSGPRGLPGPPGAPGPQGFQGPPGEPGEPGASGPMGPRGPPGPPGKNGDDGEAGKPGRPGERGPPGPQGARGLPGTAGLPGMKGHRGFSGLDGAKGDAGPAGPKGEPGSPGENGAPGQMGPRGLPGERGRPGAPGPAGARGNDGATGAAGPPGPTGPAGPPGFPGAVGAKGEGGPQGPRGSEGPQGVRGEPGPPGPAGAAGPAGNPGADGQPGAKGANGAPGIAGAPGFPGARGPSGPQGPSGPPGPKGNSGEPGAPGSKGDTGAKGEPGPTGIQGPPGPAGEEGKRGARGEPGPAGLPGPPGERGGPGSRGFPGADGVAGPKGPAGERGAPGPAGPKGSPGEAGRPGEAGLPGAKGLTGSPGSPGPDGKTGPPGPAGQDGRPGPPGPPGARGQAGVMGFPGPKGAAGEPGKAGERGVPGPPGAVGPAGKDGEAGAQGPPGPAGPAGERGEQGPAGSPGFQGLPGPAGPPGEAGKPGEQGVPGDLGAPGPSGARGERGFPGERGVQGPPGPAGPRGANGAPGNDGAKGDAGAPGAPGSQGAPGLQGMPGERGAAGLPGPKGDRGDAGPKGADGAPGKDGVRGLTGPIGPPGPAGAPGDKGEAGPSGPAGPTGARGAPGDRGEPGPPGPAGFAGPPGADGQPGAKGEPGDAGAKGDAGPPGPAGPAGPPGPIGNVGAPGPKGARGSAGPPGATGFPGAAGRVGPPGPSGNAGPPGPPGPAGKEGSKGPRGETGPAGRPGEVGPPGPPGPAGEKGAPGADGPAGAPGTPGPQGIAGQRGVVGLPGQRGERGFPGLPGPSGEPGKQGPSGASGERGPPGPMGPPGLAGPPGESGREGAPGAEGSPGRDGSPGAKGDRGETGPAGPPGAPGAPGAPGPVGPAGKSGDRGETGPAGPAGPIGPVGARGPAGPQGPRGDKGETGEQGDRGIKGHRGFSGLQGPPGPPGSPGEQGPSGASGPAGPRGPPGSAGSPGKDGLNGLPGPIGPPGPRGRTGDAGPAGPPGPPGPPGPPGPPSGGYDLSFLPQPPQEK'},\n",
        "    'Chk_COL1A1': {'offset': -7, 'sequence': 'SAGVAVPGPMGPAGPRGLPGPPGAPGPQGFQGPPGEPGEPGASGPMGPRGPAGPPGKNGDDGEAGKPGRPGQRGPPGPQGARGLPGTAGLPGMKGHRGFSGLDGAKGQPGPAGPKGEPGSPGENGAPGQMGPRGLPGERGRPGPSGPAGARGNDGAPGAAGPPGPTGPAGPPGFPGAAGAKGETGPQGARGSEGPQGARGEPGPPGPAGAAGPAGNPGADGQPGAKGATGAPGIAGAPGFPGARGPSGPQGPSGAPGPKGNSGEPGAPGNKGDTGAKGEPGPAGVQGPPGPAGEEGKRGARGEPGPAGLPGPAGERGAPGSRGFPGADGIAGPKGPPGERGSPGAVGPKGSPGEAGRPGEPGLPGAKGLTGSPGSPGPDGKTGPPGPAGQDGRPGPPGPPGARGQAGVMGFPGPKGAAGEPGKPGERGAPGPPGAVGAAGKDGEAGAQGPPGPTGPAGERGEQGPAGAPGFQGLPGPAGPPGEAGKPGEQGVPGDAGAPGPAGARGERGFPGERGVQGPPGPQGPRGANGAPGNDGAKGDAGAPGAPGNQGPPGLQGMPGERGAAGLPGAKGDRGDPGPKGADGAPGKDGLRGLTGPIGPPGPAGAPGDKGEAGPPGPAGPTGARGAPGDRGEPGPPGPAGFAGPPGADGQPGAKGETGDAGAKGDAGPPGPAGPTGAPGPAGAVGAPGPKGARGSAGPPGATGFPGAAGRVGPPGPSGNIGLPGPPGPSGKEGGKGPRGETGPAGRPGEPGPAGPPGPPGEKGSPGADGPIGAPGTPGPQGIAGQRGVVGLPGQRGERGFPGLPGPSGEPGKQGPSGSPGERGPPGPMGPPGLAGPPGEAGREGAPGAEGAPGRDGAAGPKGDRGETGPAGPPGAPGAPGAPGPVGPAGKNGDRGETGPAGPAGPPGPAGARGPAGPQGPRGDKGETGEQGDRGMKGHRGFSGLQGPPGPPGAPGEQGPSGASGPAGPRGPPGSAGAAGKDGLNGLPGPIGPPGPRGRTGEVGPVGPPGPPGPPGPPGPPSGGFDFSFLPQPPQEK'},\n",
        "    'Bov_COL1A2': {'offset': -4, 'sequence': 'GGGPGPMGLMGPRGPPGASGAPGPQGFQGPPGEPGEPGQTGPAGARGPPGPPGKAGEDGHPGKPGRPGERGVVGPQGARGFPGTPGLPGFKGIRGHNGLDGLKGQPGAPGVKGEPGAPGENGTPGQTGARGLPGERGRVGAPGPAGARGSDGSVGPVGPAGPIGSAGPPGFPGAPGPKGELGPVGNPGPAGPAGPRGEVGLPGLSGPVGPPGNPGANGLPGAKGAAGLPGVAGAPGLPGPRGIPGPVGAAGATGARGLVGEPGPAGSKGESGNKGEPGAVGQPGPPGPSGEEGKRGSTGEIGPAGPPGPPGLRGNPGSRGLPGADGRAGVMGPAGSRGATGPAGVRGPNGDSGRPGEPGLMGPRGFPGSPGNIGPAGKEGPVGLPGIDGRPGPIGPAGARGEPGNIGFPGPKGPSGDPGKAGEKGHAGLAGARGAPGPDGNNGAQGPPGLQGVQGGKGEQGPAGPPGFQGLPGPAGTAGEAGKPGERGIPGEFGLPGPAGARGERGPPGESGAAGPTGPIGSRGPSGPPGPDGNKGEPGVVGAPGTAGPSGPSGLPGERGAAGIPGGKGEKGETGLRGDIGSPGRDGARGAPGAIGAPGPAGANGDRGEAGPAGPAGPAGPRGSPGERGEVGPAGPNGFAGPAGAAGQPGAKGERGTKGPKGENGPVGPTGPVGAAGPSGPNGPPGPAGSRGDGGPPGATGFPGAAGRTGPPGPSGISGPPGPPGPAGKEGLRGPRGDQGPVGRSGETGASGPPGFVGEKGPSGEPGTAGPPGTPGPQGLLGAPGFLGLPGSRGERGLPGVAGSVGEPGPLGIAGPPGARGPPGNVGNPGVNGAPGEAGRDGNPGNDGPPGRDGQPGHKGERGYPGNAGPVGAAGAPGPQGPVGPVGKHGNRGEPGPAGAVGPAGAVGPRGPSGPQGIRGDKGEPGDKGPRGLPGLKGHNGLQGLPGLAGHHGDQGAPGAVGPAGPRGPAGPSGPAGKDGRIGQPGAVGPAGIRGSQGSQGPAGPPGPPGPPGPPGPSGGGYEFGFDGDFYR'},\n",
        "    'Chk_COL1A2': {'offset': -6, 'sequence': 'AADFGPGPMGLMGPRGPPGASGPPGPPGFQGVPGEPGEPGQTGPQGPRGPPGPPGKAGEDGHPGKPGRPGERGVAGPQGARGFPGTPGLPGFKGIRGHNGLDGQKGQPGTPGTKGEPGAPGENGTPGQPGARGLPGERGRIGAPGPAGARGSDGSAGPTGPAGPIGAAGPPGFPGAPGAKGEIGPAGNVGPTGPAGPRGEIGLPGSSGPVGPPGNPGANGLPGAKGAAGLPGVAGAPGLPGPRGIPGPPGPAGPSGARGLVGEPGPAGAKGESGNKGEPGAAGPPGPPGPSGEEGKRGSNGEPGSAGPPGPAGLRGVPGSRGLPGADGRAGVMGPAGNRGASGPVGAKGPNGDAGRPGEPGLMGPRGLPGQPGSPGPAGKEGPVGFPGADGRVGPIGPAGNRGEPGNIGFPGPKGPTGEPGKPGEKGNVGLAGPRGAPGPEGNNGAQGPPGVTGNQGAKGETGPAGPPGFQGLPGPSGPAGEAGKPGERGLHGEFGVPGPAGPRGERGLPGESGAVGPAGPIGSRGPSGPPGPDGNKGEPGNVGPAGAPGPAGPGGIPGERGVAGVPGGKGEKGAPGLRGDTGATGRDGARGLPGAIGAPGPAGGAGDRGEGGPAGPAGPAGARGIPGERGEPGPVGPSGFAGPPGAAGQPGAKGERGPKGPKGETGPTGAIGPIGASGPPGPVGAAGPAGPRGDAGPPGMTGFPGAAGRVGPPGPAGITGPPGPPGPAGKDGPRGLRGDVGPVGRTGEQGIAGPPGFAGEKGPSGEAGAAGPPGTPGPQGILGAPGILGLPGSRGERGLPGIAGATGEPGPLGVSGPPGARGPSGPVGSPGPNGAPGEAGRDGNPGNDGPPGRDGAPGFKGERGAPGNPGPSGALGAPGPHGQVGPSGKPGNRGDPGPVGPVGPAGAFGPRGLAGPQGPRGEKGEPGDKGHRGLPGLKGHNGLQGLPGLAGQHGDQGPPGNNGPAGPRGPPGPSGPPGKDGRNGLPGPIGPAGVRGSHGSQGPAGPPGPPGPPGPPGPNGGGYEVGFDAEYYR'},\n",
        "   #'Qyl_COL1A?': {'offset': -7, 'sequence': 'SGGMAVPGPM---VSGGLGVRVGFGGPQGFQGPPGEPGEPGAS----------------------------------------------------------------------------------------------------------------------------------------------------------------VSAGGEAGKPGRPGERGPPGPQGARGLPGTAGLPGMKGHRGFSGLDGAKGEPGPAGPKGEPGSPGENGAPGQMGPRGLPGERGRPGPSGPAVSIGDPGARPTPVPPPQGETGPQGARGSEGPQGARGEPGPPGPAGAAGPAGNPGADGQPGAKGATGAPGIAGAPGFPGARGPSGPQGPSGAPGPKGNSGEPGAPGNKGDTGAKGEPGPAGVQGPPGPAGEEGKRGARGEPGPAGLPGPAGERGAPGSRGFPGADGIAGPKGPPGERGAPGAVGPKGSPGEAGRPGEPGLPGAKGLTGSPGSPGPDGKTGPPGPAGQDGRPGPPGPPGARGQAGVMGFPGPKGAAGEPGKPGERGAPGPPGAVGAAGKDGEAGAQGPPGPTGPAGERGEQGPAGAPGFQGLPGPAGPPGEAGKPGEQGERGFPGERGVQGPPGPQGPRGANGAPGNDGAKGDAGAPGAPGNQGPPGLQGMPGERGAAGLPGAKGDRVRVSPPLYPIILLLPSAPSHTHSCPPPWLGAEPRGGCWGWAARGAPMWDAAPPDRSVSPLQGATGFPGAAGRVGPPGPSVSAEPPSRGGILPWHRGKGPRGETGPAGRPGEPGPAGPPGPPGEKGSPGADGPIGAPGTPGPQGIAGQRGVVGLPGQRGERGFPGLPGPSGEPGKQGPSGSPGERGPPGPMGPPGLAGPPGEAGREGAPGAEGAPGRDGAAGPKVSTQGWGDGVGPQGPRGDKGETGDRGDRGMKGHRGFSGLQGPPGPPGAPGEQGPSGASGPHRGDTRGTHSVGVPPVGEAGPVGPPGPPGPPGPPGPPSGGFDFSFLPQPPQEKAHDGGRYYR'},\n",
        "    'Bov_COL3A1': {'offset': -1, 'sequence': 'SGVAGGGIAGYPGPAGPPGPPGPPGTSGHPGAPGAPGYQGPPGEPGQAGPAGPPGPPGAIGPSGPAGKDGESGRPGRPGERGFPGPPGMKGPAGMPGFPGMKGHRGFDGRNGEKGETGAPGLKGENGVPGENGAPGPMGPRGAPGERGRPGLPGAAGARGNDGARGSDGQPGPPGPPGTAGFPGSPGAKGEVGPAGSPGSSGAPGQRGEPGPQGHAGAPGPPGPPGSNGSPGGKGEMGPAGIPGAPGLIGARGPPGPPGTNGVPGQRGAAGEPGKNGAKGDPGPRGERGEAGSPGIAGPKGEDGKDGSPGEPGANGLPGAAGERGVPGFRGPAGANGLPGEKGPPGDRGGPGPAGPRGVAGEPGRDGLPGGPGLRGIPGSPGGPGSDGKPGPPGSQGETGRPGPPGSPGPRGQPGVMGFPGPKGNDGAPGKNGERGGPGGPGPQGPAGKNGETGPQGPPGPTGPSGDKGDTGPPGPQGLQGLPGTSGPPGENGKPGEPGPKGEAGAPGIPGGKGDSGAPGERGPPGAGGPPGPRGGAGPPGPEGGKGAAGPPGPPGSAGTPGLQGMPGERGGPGGPGPKGDKGEPGSSGVDGAPGKDGPRGPTGPIGPPGPAGQPGDKGESGAPGVPGIAGPRGGPGERGEQGPPGPAGFPGAPGQNGEPGAKGERGAPGEKGEGGPPGAAGPAGGSGPAGPPGPQGVKGERGSPGGPGAAGFPGGRGPPGPPGSNGNPGPPGSSGAPGKDGPPGPPGSNGAPGSPGISGPKGDSGPPGERGAPGPQGPPGAPGPLGIAGLTGARGLAGPPGMPGARGSPGPQGIKGENGKPGPSGQNGERGPPGPQGLPGLAGTAGEPGRDGNPGSDGLPGRDGAPGAKGDRGENGSPGAPGAPGHPGPPGPVGPAGKSGDRGETGPAGPSGAPGPAGSRGPPGPQGPRGDKGETGERGAMGIKGHRGFPGNPGAPGSPGPAGHQGAVGSPGPAGPRGPVGPSGPPGKDGASGHPGPIGPPGPRGNRGERGSEGSPGHPGQPGPPGPPGAPGPCCGAGGVAAIAGVGAEK'},\n",
        "    'Chk_COL3A1': {'offset': -2, 'sequence': 'AGSVGMGYPPQPISGFPGPPGPSGPPGPPGHAGPPGSNGYQGPPGEPGQPGPSGPPGPAGMIGPAGPPGKDGEPGRPGRNGDRGIPGLPGHKGHPGMPGMPGMKGARGFDGKDGAKGDSGAPGPKGEAGQPGANGSPGQPGPRGPTGERGRPGNPGGPGAHGKDGAPGAAGPPGPPGPPGTAGFPGSPGFKGEAGPPGPAGASGSPGERGEPGPQGQAGPPGPQGPPGRAGSPGNKGEMGPSGIPGAPGLPGGRGLPGPPGTSGNPGAKGTPGEPGKNGAKGDPGPKGERGENGTPGAPGPPGEEGKRGANGEPGQNGVPGTPGERGSPGFRGLPGSNGLPGEKGPAGERGSPGPPGPSGPAGDRGQDGGPGLPGMRGLPGIPGSPGSDGKPGPPGNQGEPGRSGPPGPAGPRGQPGVMGFPGPKGNEGAPGKNGERGPGGPPGTPGPAGKNGDVGLPGPPGPAGPAGDRGEPGPSGSPGLQGLPGGPGPAGENGKPGEPGPKGDIGGPGFPGPKGENGIPGERGAQGPPGPTGARGGPGPAGSEGAKGPPGPPGAPGGTGLPGLQGMPGERGASGSPGPKGDKGEPGGKGADGLPGARGERGNVGPIGPPGPAGPPGDKGETGPAGAPGPAGSRGGPGERGEQGLPGPAGFPGAPGQNGEPGGKGERGPPGLRGEAGPPGAAGPQGGPGAPGPPGPQGVKGERGSPGGPGAAGFPGARGLPGPPGNNGSPGPPGNAGPPGKDGPPGPPGNTGPPGGSGPPGLRGEPGAPGEKGPPGARGERGTPGDPGPQGIIGSRGSTGLPGPRGLPGPAGMAGGKGEDGKPGVNGVPGERGAPGPQGPMGQRGLPGEPGRDGNPGSDGSPGRDGSPGGKGDRGESGPPGVPGPPGHPGPAGNNGAPGKAGERGFQGPPGPPGSAGPAGARGPAGPQGPRGDKGETGERGSAGIKGHRGFPGTPGLPGPPGPLGPQGAIGSPGASGARGPPGPAGPPGKDGRGGYPGPIGPPGPRGNRGESGPAGPPGQPGLPGPSGPPGPCCGGGVASLGAGEK'}\n",
        "}\n",
        "\n",
        "trypsin = {'Pig_TRYP': {'offset': 0, 'sequence': 'IVGGYTCAANSIPYQVSLNSGSHFCGGSLINSQWVVSAAHCYKSRIQVRLGEHNIDVLEGNEQFINAAKIITHPNFNGNTLDNDIMLIKLSSPATLNSRVATVSLPRSCAAAGTECLISGWGNTKSSGSSYPSLLQCLKAPVLSDSSCKSSYPGQITGNMICVGFLEGGKDSCQGDSGGPVVCNGQLQGIVSWGYGCAQKNKPGVYTKVCNYVNWIQQTIAAN'}\n",
        "}\n"
      ],
      "metadata": {
        "id": "0ZfuPxSWGpdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text Path and Amino Acid colours"
      ],
      "metadata": {
        "id": "0JtblkZ90zf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the base path as per your Google Drive structure\n",
        "STUDY_NAME = 'Dinosaur'\n",
        "PFIND_FOLDER = f'pFind_{STUDY_NAME}'\n",
        "BASE_PATH = f'/content/drive/MyDrive/Colab_Notebooks/NovorCloud/{STUDY_NAME}/{PFIND_FOLDER}/'\n",
        "\n",
        "\n",
        "\n",
        "# Amino acids colors\n",
        "amino_acids_colors = {\n",
        "    \"I\": \"#009688\", \"V\": \"#8bc34a\", \"B\": \"009688\", \"L\": \"#009688\",\n",
        "    \"F\": \"#507351\", \"C\": \"#ffeb3b\", \"M\": \"#ffeb3b\", \"A\": \"#bdd54e\",\n",
        "    \"G\": \"#9e9e9e\", \"T\": \"#ffc75e\", \"W\": \"#f49272\", \"S\": \"#ffc107\",\n",
        "    \"Y\": \"#30802f\", \"P\": \"#607d8b\", \"H\": \"#673ab7\", \"Z\": \"average\",\n",
        "    \"Q\": \"#f44336\", \"E\": \"#f44336\", \"N\": \"#e81e63\", \"D\": \"#f44336\",\n",
        "    \"X\": \"#9d9e9e\", \"K\": \"#701637\", \"R\": \"#bd3e04\"\n",
        "}\n",
        "\n",
        "#GNC Matting (next - hidded due to size)"
      ],
      "metadata": {
        "id": "hIUs0Yn-PeTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hail Mary Matching"
      ],
      "metadata": {
        "id": "wEV3Nb68RJf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for the Hail Mary approach\n",
        "allowed_mismatches_short_peptide = 3  # Allowing up to 2 mismatches for shorter peptides\n",
        "min_length_short_peptide = 10  # Minimum length for considering short peptides\n",
        "allowed_mismatches_long_peptide = 4  # Allowing up to 3 mismatches for longer peptides\n",
        "min_length_long_peptide = 15  # Minimum length for considering long peptides"
      ],
      "metadata": {
        "id": "8fEdEUT7Q-os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "McS7x8aK0MLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "def extract_protein_frequencies_and_associations(df, column_name):\n",
        "    \"\"\"\n",
        "    Extracts the frequency of each protein ID and the five most common proteins\n",
        "    listed with each ID from a specified column in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): The DataFrame containing protein data.\n",
        "    column_name (str): The name of the column with protein IDs separated by '/'.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: A DataFrame with each protein's frequency and its five most common associations.\n",
        "    \"\"\"\n",
        "    # Parse the specified column to create a list of proteins per row\n",
        "    df['Proteins_List'] = df[column_name].apply(lambda x: x.split('/'))\n",
        "\n",
        "    # Initialize a dictionary to keep count of each protein's frequency\n",
        "    protein_counts = Counter()\n",
        "    # Initialize a dictionary to keep track of proteins listed together\n",
        "    protein_associations = defaultdict(lambda: Counter())\n",
        "\n",
        "    # Count frequencies and associations\n",
        "    for proteins in df['Proteins_List']:\n",
        "        for protein in proteins:\n",
        "            protein_counts[protein] += 1\n",
        "            # Add counts for other proteins in the list to the associations\n",
        "            for associated_protein in proteins:\n",
        "                if associated_protein != protein:\n",
        "                    protein_associations[protein][associated_protein] += 1\n",
        "\n",
        "    # Prepare the final report data\n",
        "    report_data = [{\n",
        "        'Protein': protein,\n",
        "        'Frequency': count,\n",
        "        'Most_Common_Associations': [assoc for assoc, _ in protein_associations[protein].most_common(5)]\n",
        "    } for protein, count in protein_counts.items()]\n",
        "\n",
        "    # Convert report_data to a DataFrame\n",
        "    report_df = pd.DataFrame(report_data)\n",
        "\n",
        "    return report_df\n",
        "\n",
        "def find_spectra_files(base_path):\n",
        "    \"\"\"\n",
        "    Walk through the directory structure starting from base_path to find all\n",
        "    pFind-Filtered.spectra files.\n",
        "\n",
        "    Parameters:\n",
        "    - base_path (str): The base directory to start the search from.\n",
        "\n",
        "    Returns:\n",
        "    - list: A list of paths to pFind-Filtered.spectra files.\n",
        "    \"\"\"\n",
        "    spectra_files = []\n",
        "    for root, dirs, files in os.walk(base_path):\n",
        "        for file in files:\n",
        "            if file == 'pFind-Filtered.spectra':\n",
        "                spectra_files.append(os.path.join(root, file))\n",
        "    return spectra_files\n",
        "\n",
        "def combine_spectra_files(spectra_files):\n",
        "    \"\"\"\n",
        "    Combine spectra files into a single pandas DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - spectra_files (list): A list of paths to pFind-Filtered.spectra files.\n",
        "\n",
        "    Returns:\n",
        "    - DataFrame: A combined DataFrame of all spectra files.\n",
        "    \"\"\"\n",
        "    df_list = []\n",
        "    for file in spectra_files:\n",
        "        df = pd.read_csv(file, sep='\\t')  # Assuming the file is tab-separated\n",
        "        df_list.append(df)\n",
        "    combined_df = pd.concat(df_list, ignore_index=True)\n",
        "    return combined_df\n",
        "\n",
        "def match_with_one_difference(unmatched_peptide, matched_dict):\n",
        "    \"\"\"\n",
        "    Find a peptide in matched_dict with only one amino acid difference.\n",
        "\n",
        "    Args:\n",
        "        unmatched_peptide: The peptide to match.\n",
        "        matched_dict: Dictionary of peptides that have already been matched,\n",
        "                          where keys are peptide sequences and values are dictionaries\n",
        "                          containing 'gene' and 'position'.\n",
        "\n",
        "    Returns:\n",
        "        The key of the matched peptide in matched_dict if a match is found;\n",
        "        otherwise, returns None.\n",
        "    \"\"\"\n",
        "    for matched_peptide in matched_dict:\n",
        "        if len(unmatched_peptide) == len(matched_peptide):\n",
        "            # Count the number of differences\n",
        "            differences = sum(1 for p, q in zip(unmatched_peptide, matched_peptide) if p != q)\n",
        "            if differences == 1:\n",
        "                return matched_peptide\n",
        "    return None\n",
        "\n",
        "def isobaric_and_deamidation_matching(peptide1, peptide2, max_diff=1):\n",
        "    \"\"\"\n",
        "    Compares two peptides for similarity, allowing for isobaric amino acids (I/L) and\n",
        "    potential deamidation (N/D, Q/E) as equivalent, up to a max difference.\n",
        "\n",
        "    Parameters:\n",
        "    - peptide1, peptide2: Peptides to compare.\n",
        "    - max_diff: Maximum allowed differences (default 1).\n",
        "\n",
        "    Returns:\n",
        "    - Boolean indicating whether the peptides are considered similar under the given rules.\n",
        "    \"\"\"\n",
        "    if len(peptide1) != len(peptide2):\n",
        "        return False  # Peptides of different lengths are automatically not similar\n",
        "\n",
        "    diff_count = 0\n",
        "    for a, b in zip(peptide1, peptide2):\n",
        "        if a == b:\n",
        "            continue  # Identical amino acids\n",
        "        elif (a in ['I', 'L'] and b in ['I', 'L']) or (a in ['N', 'D'] and b in ['N', 'D']) or (a in ['Q', 'E'] and b in ['Q', 'E']):\n",
        "            continue  # Treat specific substitutions as equivalent\n",
        "        else:\n",
        "            diff_count += 1\n",
        "            if diff_count > max_diff:\n",
        "                return False  # Exceeds max allowed differences\n",
        "\n",
        "    return True  # Peptides are similar within the allowed differences\n",
        "\n",
        "def iteratively_match_peptides(filtered_peptides, matched_dict):\n",
        "    \"\"\"\n",
        "    Attempts to match peptides taking into account isobaric amino acids (I/L) and\n",
        "    deamidation (N/D, Q/E), until no new matches can be found.\n",
        "\n",
        "    Parameters:\n",
        "    - filtered_peptides: A list of peptides to match.\n",
        "    - matched_dict: A dictionary of peptides already matched with their gene and position.\n",
        "\n",
        "    Returns:\n",
        "    - A tuple containing updated dictionaries of matched peptides and unmatched peptides.\n",
        "    \"\"\"\n",
        "    additional_matches = {}\n",
        "    unmatched_dict = {}\n",
        "\n",
        "    while True:\n",
        "        new_matches_found = False\n",
        "        for peptide in filtered_peptides:\n",
        "            if peptide not in matched_dict:\n",
        "                for candidate in matched_dict.keys():\n",
        "                    if isobaric_and_deamidation_matching(peptide, candidate):\n",
        "                        additional_matches[peptide] = matched_dict[candidate]\n",
        "                        new_matches_found = True\n",
        "                        break\n",
        "                if peptide not in additional_matches:\n",
        "                    unmatched_dict[peptide] = \"No match found\"\n",
        "\n",
        "        if not new_matches_found:\n",
        "            break  # No new matches in this iteration\n",
        "\n",
        "        matched_dict.update(additional_matches)  # Add new matches\n",
        "        additional_matches.clear()  # Reset for next iteration\n",
        "\n",
        "    return matched_dict, unmatched_dict\n",
        "\n",
        "def hail_mary_match(peptide, candidate_peptides, allowed_mismatches, min_length):\n",
        "    \"\"\"\n",
        "    Attempt to match a peptide with candidates allowing for a specified number of mismatches,\n",
        "    but only if the peptide meets a minimum length requirement.\n",
        "\n",
        "    Parameters:\n",
        "    - peptide (str): The peptide to match.\n",
        "    - candidate_peptides (dict): Dictionary of peptides already matched with details.\n",
        "    - allowed_mismatches (int): The number of mismatches allowed in the match. This parameter dynamically\n",
        "      changes based on whether the peptide is considered short or long.\n",
        "    - min_length (int): The minimum length of peptide to consider for matching. This parameter dynamically\n",
        "      changes based on whether the peptide is being evaluated for short or long criteria.\n",
        "\n",
        "    Returns:\n",
        "    - str or None: The closest matching peptide if a match is found; otherwise, None.\n",
        "    \"\"\"\n",
        "    if len(peptide) < min_length:\n",
        "        return None  # Skip peptides shorter than the minimum length requirement.\n",
        "\n",
        "    for candidate, details in candidate_peptides.items():\n",
        "        if len(candidate) != len(peptide):\n",
        "            continue  # Skip if lengths do not match.\n",
        "\n",
        "        # Calculate the number of mismatches between the candidate and the peptide.\n",
        "        mismatches = sum(1 for a, b in zip(candidate, peptide) if a != b)\n",
        "\n",
        "        if mismatches <= allowed_mismatches:\n",
        "            return candidate  # Return the first candidate that matches within the allowed mismatches.\n",
        "\n",
        "    return None  # No suitable match found.\n",
        "\n",
        "\n",
        "def parse_and_update_df(sequence, matched_dict): #combined_df\n",
        "    \"\"\"\n",
        "    Check if the sequence matches an entry in the matched_dict and return gene and position.\n",
        "\n",
        "    Parameters:\n",
        "    - sequence (str): The peptide sequence to check.\n",
        "    - matched_dict (dict): Dictionary with peptide sequences as keys and details as values.\n",
        "\n",
        "    Returns:\n",
        "    - tuple: (gene, position) if match is found; (None, None) otherwise.\n",
        "    \"\"\"\n",
        "    if sequence in matched_dict:\n",
        "        # Extract gene and position from the matched entry\n",
        "        gene = matched_dict[sequence]['gene']\n",
        "        position = matched_dict[sequence]['position']\n",
        "        return gene, position\n",
        "    else:\n",
        "        # Return None or placeholders if no match is found\n",
        "        return None, None\n",
        "\n",
        "def find_match_and_update(row, matched_dict):\n",
        "    \"\"\"\n",
        "    Check for a match in matched_dict and return GCN, start_position.\n",
        "\n",
        "    Parameters:\n",
        "    - row: DataFrame row containing 'Sequence'.\n",
        "    - matched_dict: Dictionary with peptides as keys and details (gene, position) as values.\n",
        "\n",
        "    Returns:\n",
        "    - GCN: Gene name if match is found; otherwise None.\n",
        "    - start_position: Position if match is found; otherwise None.\n",
        "    \"\"\"\n",
        "    sequence = row['Sequence']\n",
        "    if sequence in matched_dict:\n",
        "        gene = matched_dict[sequence]['gene']\n",
        "        position = matched_dict[sequence]['position']\n",
        "        return pd.Series([gene, position])\n",
        "    else:\n",
        "        return pd.Series([None, None])\n",
        "\n",
        "def parse_modifications(mod_str):\n",
        "    \"\"\"\n",
        "    Parses a string containing modification data into a structured list.\n",
        "\n",
        "    :param mod_str: A string representing modifications in the format \"position,Modification[AminoAcid];\"\n",
        "    :return: A list of tuples, each representing (position, modification type, amino acid).\n",
        "    \"\"\"\n",
        "    if pd.isnull(mod_str):\n",
        "        return []\n",
        "\n",
        "    # Split the string into individual modifications\n",
        "    mods = mod_str.strip(';').split(';')\n",
        "    parsed_mods = []\n",
        "\n",
        "    for mod in mods:\n",
        "        parts = mod.split(',')\n",
        "        if len(parts) == 2:\n",
        "            pos, mod_detail = parts\n",
        "            mod_type = mod_detail.split('[')[0]  # Extract modification type\n",
        "            aa = mod_detail.split('[')[1].rstrip(']')  # Extract amino acid\n",
        "            parsed_mods.append((int(pos), mod_type, aa))\n",
        "\n",
        "    return parsed_mods\n",
        "\n",
        "def parse_peptide(peptide):\n",
        "    \"\"\"\n",
        "    Parses peptide strings to identify amino acids and extract them along with their positions.\n",
        "\n",
        "    :param peptide: A string representation of a peptide.\n",
        "    :return: A list of tuples, each representing an amino acid and its position in the peptide.\n",
        "    \"\"\"\n",
        "    # A simple pattern that matches each amino acid in the sequence.\n",
        "    aa_pattern = re.compile(r'[A-Z]')\n",
        "    parsed_peptides = []\n",
        "    pos = 1  # Position initialization\n",
        "\n",
        "    for match in aa_pattern.finditer(peptide):\n",
        "        aa = match.group()  # Extract the amino acid\n",
        "        parsed_peptides.append((aa, pos))\n",
        "        pos += 1  # Increment position for each amino acid\n",
        "\n",
        "    return parsed_peptides\n",
        "\n",
        "def expand_df(df):\n",
        "    \"\"\"\n",
        "    Expands a DataFrame by processing each peptide sequence and constructing detailed rows\n",
        "    for each amino acid within the peptide sequences, including the simplified sample name.\n",
        "\n",
        "    :param df: A pandas DataFrame containing peptide information.\n",
        "    :return: An expanded DataFrame with detailed amino acid and sample name information.\n",
        "    \"\"\"\n",
        "    expanded_rows = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        amino_acids = parse_peptide(row['Sequence'])\n",
        "        spp_gcn = row['spp&GCN'].split('_')\n",
        "        if len(spp_gcn) != 2:\n",
        "            continue\n",
        "        GCN_species, GCN = spp_gcn\n",
        "\n",
        "        # Extract the simplified file name from the 'File_Name' column\n",
        "        file_name = row['File_Name']\n",
        "        simplified_file_name = \"_\".join(file_name.split(\"_\")[:2])\n",
        "\n",
        "        for aa, pos in amino_acids:\n",
        "            protein_position = int(row['start_position'] + pos - 1)  # Convert to integer\n",
        "            expanded_row = {\n",
        "                'sample_name': simplified_file_name,  # Adding the simplified file name\n",
        "                'GCN': GCN,\n",
        "                'GCN_species': GCN_species,\n",
        "                'aa': aa,  # Now filled with the amino acid\n",
        "                'position': protein_position,\n",
        "                'ptm': '',  # Assuming no PTMs are considered for this part\n",
        "                'confidence': None,  # Assuming confidence is not applicable\n",
        "                'spectraId': row['Scan_No'],\n",
        "                'mz': row['Exp.MH+'],\n",
        "                'z': row['Charge'],\n",
        "                'pepMass': row['Calc.MH+'],\n",
        "                'err': row['Mass_Shift(Exp.-Calc.)'],\n",
        "                'score': row['Final_Score'],\n",
        "                'scanNum': row['Scan_No'],\n",
        "                'peptide_gene_name': row['Proteins'],\n",
        "                'RT': None,  # Assuming RT is not applicable or missing\n",
        "                'ppm': None,  # Assuming ppm needs to be calculated or is missing\n",
        "\n",
        "            }\n",
        "            expanded_rows.append(expanded_row)\n",
        "\n",
        "    return pd.DataFrame(expanded_rows)\n",
        "\n"
      ],
      "metadata": {
        "id": "Tlmd4BGsjYvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load files"
      ],
      "metadata": {
        "id": "3DtwTX5xGJBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find pFind-Filtered.spectra files\n",
        "spectra_files = find_spectra_files(BASE_PATH)\n",
        "\n",
        "# Combine into a single DataFrame\n",
        "combined_df = combine_spectra_files(spectra_files)\n",
        "#Add the length of the peptide\n",
        "combined_df['peptide_length'] = combined_df['Sequence'].apply(len)\n",
        "#----------------------Reporting\n",
        "#combined_df.shape\n",
        "#combined_df.info()\n",
        "##combined_df.describe()\n",
        "#combined_df['Sequence'].nunique()\n",
        "#combined_df['Miss.Clv.Sites'].nunique()\n",
        "combined_df.head()"
      ],
      "metadata": {
        "id": "M51comiRGK7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Report on the most frequent proteins - this is very SLOW!!!\n",
        "# report_df = extract_protein_frequencies_and_associations(combined_df, 'Proteins')\n",
        "\n",
        "# # Display or export `report_df` as needed\n",
        "# print(report_df)"
      ],
      "metadata": {
        "id": "3FNQCIQo1_wT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Writing this report.csv\n",
        "# Construct the file path first\n",
        "csv_file_path = f'{BASE_PATH}/{STUDY_NAME}_prot_freq.csv'\n",
        "\n",
        "# Export the DataFrame to CSV using the correct method name\n",
        "report_df.to_csv(csv_file_path)"
      ],
      "metadata": {
        "id": "j0vgjVsK37iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df.head()"
      ],
      "metadata": {
        "id": "eCpbz9TZ0dLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Find Collagen motif\n",
        "Iterates through each peptide in unique_peptides.\n",
        "Uses a generator expression within all() to check if every third character, starting from the offset determined by len(peptide) % 3, is a 'G'.\n",
        "This method directly reflects the requirement for 'G' to be every third character after an initial offset and accounts for sequences that may not start with 'G' or might be truncated."
      ],
      "metadata": {
        "id": "nZo29vtF3BKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract unique peptides from the 'Sequence' column without altering the combined DataFrame\n",
        "unique_peptides = combined_df['Sequence'].unique().tolist()\n",
        "\n",
        "#Iterates through each peptide in unique_peptides.\n",
        "#Uses a generator expression within all() to check if every third character, starting from the offset determined by len(peptide) % 3, is a 'G'.\n",
        "#reflects the requirement for 'G' to be every 3rd character and accounts for sequences that may not start with 'G' or might be truncated.\n",
        "\n",
        "filtered_peptides = [\n",
        "    peptide for peptide in unique_peptides\n",
        "    if all(peptide[i] == 'G' for i in range(len(peptide) % 3, len(peptide), 3))\n",
        "]\n",
        "\n",
        "# Initialize dictionaries for tracking peptide matches\n",
        "matched_dict = {}  # Stores peptides found in collagen sequences with gene and position\n",
        "# Additional dictionaries for tracking Hail Mary Matching\n",
        "hail_mary_matches_short = {}\n",
        "hail_mary_matches_long = {}\n",
        "\n",
        "# First pass: Find direct matches in collagen sequences\n",
        "for peptide in filtered_peptides:\n",
        "    for gene, details in collagen_sequences.items():\n",
        "        sequence = details['sequence']\n",
        "        offset = details['offset']\n",
        "        position = sequence.find(peptide)\n",
        "\n",
        "        if position != -1:  # Peptide found in the sequence\n",
        "            corrected_position = position + offset  # Adjust for sequence offset\n",
        "            matched_dict[peptide] = {'gene': gene, 'position': corrected_position}\n",
        "            break  # Exit loop after finding the first match\n",
        "\n",
        "\n",
        "# Finding both direct matches and near matches iteratively\n",
        "matched_dict, unmatched_peptides = iteratively_match_peptides(filtered_peptides, matched_dict)\n",
        "\n",
        "# Attempt Hail Mary matching for unmatched peptides\n",
        "\n",
        "for peptide, details in unmatched_peptides.items():# Convert to list to avoid RuntimeError\n",
        "    if len(peptide) >= min_length_short_peptide:\n",
        "        match = hail_mary_match(peptide, matched_dict, allowed_mismatches_short_peptide, min_length_short_peptide)\n",
        "        if match:\n",
        "            hail_mary_matches_short[peptide] = matched_dict[match]\n",
        "    if len(peptide) >= min_length_long_peptide:\n",
        "        match = hail_mary_match(peptide, matched_dict, allowed_mismatches_long_peptide, min_length_long_peptide)\n",
        "        if match:\n",
        "            hail_mary_matches_long[peptide] = matched_dict[match]\n",
        "\n",
        "\n",
        "# Before Hail Mary matching\n",
        "total_matched_before_hail_mary = len(matched_dict)\n",
        "total_unmatched_before_hail_mary = len(filtered_peptides) - total_matched_before_hail_mary\n",
        "\n",
        "print(f\"Total matched peptides before Hail Mary approach: {total_matched_before_hail_mary}\")\n",
        "print(f\"Total unmatched peptides before Hail Mary approach: {total_unmatched_before_hail_mary}\")\n",
        "\n",
        "# Update matched_peptides with (more desparate) Hail Mary matches\n",
        "matched_dict.update(hail_mary_matches_short)\n",
        "matched_dict.update(hail_mary_matches_long)\n",
        "\n",
        "# Recalculate unmatched peptides after Hail Mary matches\n",
        "for peptide in hail_mary_matches_short.keys():\n",
        "    unmatched_peptides.pop(peptide, None)\n",
        "for peptide in hail_mary_matches_long.keys():\n",
        "    unmatched_peptides.pop(peptide, None)\n",
        "\n",
        "# After Hail Mary matching\n",
        "total_matched_after_hail_mary = len(matched_dict)\n",
        "total_unmatched_after_hail_mary = len(filtered_peptides) - total_matched_after_hail_mary\n",
        "\n",
        "\n",
        "# Report the parameters used for the Hail Mary approach\n",
        "print(\"The Hail Mary approach is currently using:\")\n",
        "print(f\"- {allowed_mismatches_short_peptide} mismatches in peptides of length greater than {min_length_short_peptide}.\")\n",
        "print(f\"- {allowed_mismatches_long_peptide} mismatches in peptides greater than {min_length_long_peptide}.\\n\")\n",
        "\n",
        "print(f\"Total matched peptides after Hail Mary approach: {total_matched_after_hail_mary}\")\n",
        "print(f\"Total unmatched peptides after Hail Mary approach: {total_unmatched_after_hail_mary}\")\n",
        "\n",
        "\n",
        "# # #Print unmatched peptides to inspect those without any match\n",
        "# if unmatched_peptides:\n",
        "#     print(\"There was no match to the following peptides:\")\n",
        "#     for peptide in unmatched_peptides.keys():\n",
        "#         print(peptide)\n",
        "\n",
        "# Assuming matched_peptides is your dictionary\n",
        "for peptide, details in islice(matched_dict.items(), 10):\n",
        "    print(f\"Peptide: {peptide}, Gene: {details['gene']}, Position: {details['position']}\")"
      ],
      "metadata": {
        "id": "eRB4WWmtHvY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update combined_df with new columns 'GCN' and 'position' based on matches\n",
        "combined_df[['spp&GCN', 'start_position']] = combined_df.apply(find_match_and_update, axis=1, args=(matched_dict,))\n"
      ],
      "metadata": {
        "id": "TBh_XSKRWLfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combined_df.shape\n",
        "#combined_df.info()\n",
        "##combined_df.describe()\n",
        "#combined_df['Sequence'].nunique()\n",
        "#combined_df['Miss.Clv.Sites'].nunique()\n",
        "combined_df.head()\n",
        "list(combined_df.columns)\n",
        "#print(combined_df[['spp&GCN', 'Sequence','Proteins', 'Positions', 'start_position']].head(40))\n",
        "spp_gcn_counts = combined_df['spp&GCN'].value_counts()\n",
        "\n",
        "# Print the counts of different entries\n",
        "print(spp_gcn_counts)\n",
        "\n",
        "# Replace 'None' and empty strings with np.nan for uniformity\n",
        "combined_df['spp&GCN'] = combined_df['spp&GCN'].replace({None: np.nan, '': np.nan})\n",
        "\n",
        "# Filter rows where 'spp&GCN' is not NaN\n",
        "filtered_combined_df = combined_df.dropna(subset=['spp&GCN'])\n",
        "\n",
        "# Now, filtered_combined_df contains only the rows where 'spp&GCN' is not None, NaN, or blank\n",
        "# You can perform your operations on filtered_combined_df\n",
        "\n",
        "# Example operation: Print the head of the filtered DataFrame to verify the filtering\n",
        "print(filtered_combined_df.head())\n"
      ],
      "metadata": {
        "id": "s-YlqRWLwfnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand combined_df to detail each peptide's amino acid positions and associated PTMs\n",
        "exp_df = expand_df(filtered_combined_df)"
      ],
      "metadata": {
        "id": "1RHve46MY0BD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the expanded DataFrame to verify the result\n",
        "print(exp_df.head())\n",
        "list(exp_df.columns)"
      ],
      "metadata": {
        "id": "Pn9kqvWuKPQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Find the 10 most common GCNs\n",
        "top_10_gcn_counts = combined_df['spp&GCN'].value_counts().head(30)\n",
        "top_10_gcns = top_10_gcn_counts.index.tolist()\n",
        "\n",
        "# Initialize a report dictionary\n",
        "report = {}\n",
        "\n",
        "# Step 2: Aggregate information for each GCN, including peptide length for end position calculation\n",
        "for gcn in top_10_gcns:\n",
        "    # Filter rows for the current GCN\n",
        "    gcn_rows = combined_df[combined_df['spp&GCN'] == gcn]\n",
        "\n",
        "    # Calculate number of rows (identified scans)\n",
        "    num_rows = len(gcn_rows)\n",
        "\n",
        "    # Start positions are derived directly from 'modal_start_position'\n",
        "    start_positions = gcn_rows['start_position'].min()\n",
        "\n",
        "    # Calculate end positions by adding the length of the peptide to the start position\n",
        "    # and find the maximum value for the end position\n",
        "    # Note: Assuming the 'length' column exists and represents the length of the peptide\n",
        "    end_positions = (gcn_rows['start_position'] + gcn_rows['peptide_length'] - 1).max()\n",
        "    # The '-1' accounts for the fact that the start position is inclusive in the peptide length\n",
        "\n",
        "    # The total length covered is estimated as the difference between the max end and min start position\n",
        "    total_length_covered = end_positions - start_positions + 1  # +1 to include both start and end in the range\n",
        "\n",
        "    # Populate the report dictionary\n",
        "    report[gcn] = {\n",
        "        'Number of Rows': num_rows,\n",
        "        'Start Position': start_positions,\n",
        "        'End Position': end_positions,\n",
        "        'Total Length Covered': total_length_covered\n",
        "    }\n",
        "\n",
        "# Convert the report dictionary to a DataFrame for better visualization and analysis\n",
        "report_df = pd.DataFrame.from_dict(report, orient='index')\n",
        "\n",
        "print(report_df)"
      ],
      "metadata": {
        "id": "nvouls-9Wtb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Writing exp.csv\n",
        "# Construct the file path first\n",
        "csv_file_path = f'{BASE_PATH}/{STUDY_NAME}exp.csv'\n",
        "\n",
        "# Export the DataFrame to CSV using the correct method name\n",
        "exp_df.to_csv(csv_file_path)"
      ],
      "metadata": {
        "id": "8pJQpogBKkeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plotting"
      ],
      "metadata": {
        "id": "uF1qYlG7MNih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out rows where 'GCN' is not specified or is NaN\n",
        "df_filtered = exp_df[(exp_df['GCN'] != \"_\") & pd.notna(exp_df['GCN'])]\n",
        "\n",
        "# Get the top 5 most common GCNs\n",
        "top_GCNs = df_filtered['GCN'].value_counts().head(5).index.tolist()\n",
        "\n",
        "# Filter the DataFrame to only include these top GCNs\n",
        "df_top = df_filtered[df_filtered['GCN'].isin(top_GCNs)]\n",
        "\n",
        "print(df_top.head())"
      ],
      "metadata": {
        "id": "Jv10pR1OMPeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a dictionary to hold data for each GCN\n",
        "data_for_plotting = {gcn: None for gcn in top_GCNs}\n",
        "\n",
        "for gcn in top_GCNs:\n",
        "    # Filter the DataFrame for the current GCN\n",
        "    df_gcn = df_top[df_top['GCN'] == gcn]\n",
        "\n",
        "    # Create a DataFrame with all positions from min to max for the GCN\n",
        "    all_positions = pd.DataFrame({'position': range(df_gcn['position'].min(), df_gcn['position'].max() + 1)})\n",
        "\n",
        "    # Merge this DataFrame with the existing df_gcn on 'position' to include all positions\n",
        "    # Use 'outer' merge to ensure all positions are included, filling missing values with 'No Data' or suitable defaults\n",
        "    df_gcn_full = pd.merge(all_positions, df_gcn, on='position', how='left')\n",
        "\n",
        "    # Fill missing values in 'aa' with 'No Data' and other columns as needed\n",
        "    df_gcn_full['aa'].fillna('No Data', inplace=True)\n",
        "    # Handle other columns that may require default values after merge\n",
        "    # Example: df_gcn_full['confidence'].fillna(0, inplace=True)\n",
        "\n",
        "    data_for_plotting[gcn] = df_gcn_full"
      ],
      "metadata": {
        "id": "wSYvVwi1MUD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the DataFrame by 'sample_name', 'GCN', and 'GCN_species'\n",
        "grouped = exp_df.groupby(['sample_name', 'GCN', 'GCN_species'])\n",
        "\n",
        "for (sample_name, GCN, GCN_species), group in grouped:\n",
        "    # Group by 'position' and 'aa', then count instances\n",
        "    aa_counts = group.groupby(['position', 'aa']).size().unstack(fill_value=0)\n",
        "\n",
        "    # Ensure all positions are included, even if some have no data\n",
        "    all_positions = range(group['position'].min(), group['position'].max() + 1)\n",
        "    aa_counts = aa_counts.reindex(all_positions, fill_value=0)\n",
        "\n",
        "    # Prepare data for stacking in histogram\n",
        "    bottoms = np.zeros(len(aa_counts))\n",
        "\n",
        "    # Set up the plot\n",
        "    plt.figure(figsize=(14, 8))\n",
        "\n",
        "    # Colors for amino acids\n",
        "    amino_acids = list(aa_counts.columns)\n",
        "    colors = [amino_acids_colors.get(aa, '#000000') for aa in amino_acids]  # Fallback to black if aa not in color dict\n",
        "\n",
        "    for aa, color in zip(amino_acids, colors):\n",
        "        plt.bar(aa_counts.index, aa_counts[aa], bottom=bottoms, label=aa, color=color)\n",
        "        bottoms += aa_counts[aa].values\n",
        "\n",
        "    plt.title(f'Stacked Histogram of Amino Acid Instances for {sample_name}, {GCN}, {GCN_species}')\n",
        "    plt.xlabel('Position')\n",
        "    plt.ylabel('Number of Instances')\n",
        "    plt.legend(title='Amino Acid', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "VmjZc9V4ELXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the DataFrame by 'sample_name', 'GCN', and 'GCN_species'\n",
        "grouped = exp_df.groupby(['sample_name', 'GCN', 'GCN_species'])\n",
        "\n",
        "for (sample_name, GCN, GCN_species), group in grouped:\n",
        "    # Group by 'position' and 'aa', then count instances\n",
        "    aa_counts = group.groupby(['position', 'ptm']).size().unstack(fill_value=0)\n",
        "\n",
        "    # Ensure all positions are included, even if some have no data\n",
        "    all_positions = range(group['position'].min(), group['position'].max() + 1)\n",
        "    aa_counts = aa_counts.reindex(all_positions, fill_value=0)\n",
        "\n",
        "    # Prepare data for stacking in histogram\n",
        "    bottoms = np.zeros(len(aa_counts))\n",
        "\n",
        "    # Set up the plot\n",
        "    plt.figure(figsize=(14, 8))\n",
        "\n",
        "    # Colors for amino acids\n",
        "    amino_acids = list(aa_counts.columns)\n",
        "    colors = [amino_acids_colors.get(aa, '#000000') for aa in amino_acids]  # Fallback to black if aa not in color dict\n",
        "\n",
        "    for aa, color in zip(amino_acids, colors):\n",
        "        plt.bar(aa_counts.index, aa_counts[aa], bottom=bottoms, label=aa, color=color)\n",
        "        bottoms += aa_counts[aa].values\n",
        "\n",
        "    plt.title(f'Stacked Histogram of Modification for {sample_name}, {GCN}, {GCN_species}')\n",
        "    plt.xlabel('Position')\n",
        "    plt.ylabel('Number of Instances')\n",
        "    plt.legend(title='Modifications', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "I4KHuqOJsgWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a GCN for demonstration. Replace 'COL1A1' with your GCN of interest\n",
        "gcn_of_interest = 'COL1A2'\n",
        "df_gcn = df_top[df_top['GCN'] == gcn_of_interest]\n",
        "\n",
        "# Group by position and aa, then count instances\n",
        "aa_counts = df_gcn.groupby(['position', 'aa']).size().unstack(fill_value=0)\n",
        "\n",
        "# Ensure all positions are included, even if some have no data\n",
        "all_positions = range(df_gcn['position'].min(), df_gcn['position'].max() + 1)\n",
        "aa_counts = aa_counts.reindex(all_positions, fill_value=0)\n",
        "\n",
        "# Prepare data for stacking in histogram\n",
        "bottoms = np.zeros(len(aa_counts))\n",
        "\n",
        "# Set up the plot\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "# Colors for amino acids\n",
        "amino_acids = list(aa_counts.columns)\n",
        "colors = [amino_acids_colors.get(aa, '#000000') for aa in amino_acids]  # Fallback to black if aa not in color dict\n",
        "\n",
        "for aa, color in zip(amino_acids, colors):\n",
        "    plt.bar(aa_counts.index, aa_counts[aa], bottom=bottoms, label=aa, color=color)\n",
        "    bottoms += aa_counts[aa].values\n",
        "\n",
        "plt.title(f'Stacked Histogram of Amino Acid Instances for {gcn_of_interest}')\n",
        "plt.xlabel('Position')\n",
        "plt.ylabel('Number of Instances')\n",
        "plt.legend(title='Amino Acid', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2rLMc430Ms6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Q9ewqk2AMO6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming exp_df is your DataFrame\n",
        "\n",
        "# Calculate the percentage of modified sites per position\n",
        "# First, calculate total instances and modified instances per position\n",
        "mod_counts = exp_df.groupby(['position', 'GCN_species', 'ptm']).size().unstack(fill_value=0)\n",
        "total_counts = exp_df.groupby(['position', 'GCN_species']).size().rename('total')\n",
        "\n",
        "# Join the counts to calculate percentages\n",
        "mod_counts = mod_counts.join(total_counts)\n",
        "mod_counts['percentage'] = mod_counts.apply(lambda row: row[1] / row['total'] * 100, axis=1)\n",
        "\n",
        "# Prepare data for plotting\n",
        "positions = mod_counts.index.get_level_values('position').unique()\n",
        "gcn_species = LabelEncoder().fit_transform(mod_counts.index.get_level_values('GCN_species'))\n",
        "sizes = mod_counts['total'] * 10  # Scale the sizes as needed\n",
        "colors = gcn_species\n",
        "\n",
        "# Create the scatter plot\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "scatter = ax.scatter(positions, mod_counts['percentage'], c=colors, s=sizes, alpha=0.7, edgecolors='none', cmap=\"Set1\")\n",
        "ax.set_title('Percentage of Modified Sites by Position')\n",
        "ax.set_xlabel('Position')\n",
        "ax.set_ylabel('Percentage of Modified Sites')\n",
        "ax.grid(visible=True, which='major', axis='both')\n",
        "\n",
        "# Add a color legend for GCN_species\n",
        "handles, labels = scatter.legend_elements()\n",
        "actual_labels = LabelEncoder().inverse_transform([int(label) for label in labels])\n",
        "color_legend = ax.legend(handles, actual_labels, loc=\"upper left\", title=\"GCN_species\", bbox_to_anchor=(1, 1))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SHv5P_zpuyec"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}