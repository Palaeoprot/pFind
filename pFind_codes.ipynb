{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP+iplBUsGJkxtga5axuLVv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Palaeoprot/pFind/blob/main/pFind_codes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pFind3 Routines\n",
        "[Github](https://github.com/pFindStudio/pFind3)\n",
        "\n",
        "\n",
        "Open-pFind enables precise, comprehensive and rapid peptide identification in shotgun proteomics Hao Chi, Chao Liu, Hao Yang, Wen-Feng Zeng, Long Wu, Wen-Jing Zhou, Xiu-Nan Niu, Yue-He Ding, Yao Zhang, Rui-Min Wang, Zhao-Wei Wang, Zhen-Lin Chen, Rui-Xiang Sun, Tao Liu, Guang-Ming Tan, Meng-Qiu Dong, Ping Xu, Pei-Heng Zhang, Si-Min He. BioRxiv, Mar. 20, 2018.\n"
      ],
      "metadata": {
        "id": "E9lx8h8tBurq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Analytical Scripts\n"
      ],
      "metadata": {
        "id": "lNSR-u5cC5f_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scripts are used for compare two or more identification results from pFind 3.\n",
        "\n",
        "Modified from\n",
        "[https://github.com/daheitu/scripts_for_pFind3_protocol.io](https://github.com/daheitu/scripts_for_pFind3_protocol.io)\n",
        "\n",
        "\n",
        "Create a new folder in a desired location and give it a name.\n",
        "\n",
        "To compare across samples either the identified proteins or PTMs, respectively, copy either\n",
        "###“pFind_protein_contrast_script.py”\n",
        "or\n",
        "###“pFind_PTM_contrast_script.py”\n",
        "\n",
        "and the different pFind.protein files to be compared into this new folder. Note that each pFind.protein file should be renamed before it comes to this folder.\n",
        "\n",
        "The file name should be a ready reminder of the sample and the purpose of the search.\n",
        "\n",
        "Open “pFind_protein_contrast_script.py” or “pFind_PTM_contrast_script.py” using ‘Notepad++’ or another editor, specify the path of the new folder and save.\n",
        "\n",
        "You may change the name of the output file if you dislike the default one.\n",
        "\n",
        "\n",
        "Header annotation of pFind_protein_contrast_result.txt and that of or pFind_PTM_contrast_result.txt can be found in Table S9 and Table S10 in SI."
      ],
      "metadata": {
        "id": "Malx9XS_5DX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global Varibles"
      ],
      "metadata": {
        "id": "taooEB7d0GxA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Packages"
      ],
      "metadata": {
        "id": "R1Ec3Q5d0nzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data manipulation:\n",
        "import pandas as pd\n",
        "from itertools import islice\n",
        "#import sketch\n",
        "from collections import Counter\n",
        "\n",
        "# Debugging:\n",
        "import traceback\n",
        "\n",
        "# File I/O and path handling:\n",
        "import os\n",
        "import copy, os\n",
        "import re\n",
        "import requests\n",
        "import json\n",
        "from typing import Dict, Any\n",
        "\n",
        "\n",
        "# Numerical analysis and statistics:\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from statistics import mode, multimode  # Consider removing if unused\n",
        "\n",
        "# Data visualization:\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import to_rgba\n",
        "\n",
        "# Third-party modules (Commented out modules can be imported as needed):\n",
        "# from Bio import SeqIO  # Only import if used\n",
        "# from icecream import ic  # Import on demand if needed\n",
        "\n",
        "# Google Colab specific for mounting Google Drive:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "GiAz-Tf_OGox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text Path and Amino Acid colours"
      ],
      "metadata": {
        "id": "0JtblkZ90zf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the base path as per your Google Drive structure\n",
        "STUDY_NAME = 'Dinosaur'\n",
        "PFIND_FOLDER = f'pFind_{STUDY_NAME}'\n",
        "BASE_PATH = f'/content/drive/MyDrive/Colab_Notebooks/NovorCloud/{STUDY_NAME}/{PFIND_FOLDER}/'\n",
        "\n",
        "\n",
        "\n",
        "# Amino acids colors\n",
        "amino_acids_colors = {\n",
        "    \"I\": \"#009688\", \"V\": \"#8bc34a\", \"B\": \"009688\", \"L\": \"#009688\",\n",
        "    \"F\": \"#507351\", \"C\": \"#ffeb3b\", \"M\": \"#ffeb3b\", \"A\": \"#bdd54e\",\n",
        "    \"G\": \"#9e9e9e\", \"T\": \"#ffc75e\", \"W\": \"#f49272\", \"S\": \"#ffc107\",\n",
        "    \"Y\": \"#30802f\", \"P\": \"#607d8b\", \"H\": \"#673ab7\", \"Z\": \"average\",\n",
        "    \"Q\": \"#f44336\", \"E\": \"#f44336\", \"N\": \"#e81e63\", \"D\": \"#f44336\",\n",
        "    \"X\": \"#9d9e9e\", \"K\": \"#701637\", \"R\": \"#bd3e04\"\n",
        "}\n",
        "\n",
        "#GNC Matting (next - hidded due to size)"
      ],
      "metadata": {
        "id": "hIUs0Yn-PeTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ignore all of this - this was stuff I was messing aroud witn by do not want to delete"
      ],
      "metadata": {
        "id": "irpgRICNLgTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = \"\"\"\n",
        "IPR000225 (94%);IPR003613 (93%);IPR011989 (93%)\n",
        "IPR000515 (9%);IPR035906 (9%);IPR027417 (7%)\n",
        "IPR000742 (50%);IPR000885 (50%);IPR002369 (50%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001007 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR001791 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (23%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (25%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (33%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (50%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (50%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (52%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (57%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (58%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (58%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (58%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (62%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (67%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (73%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (73%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (75%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (75%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (75%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (75%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (80%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (80%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (80%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (81%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (83%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (83%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (83%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (83%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (86%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (87%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (88%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (88%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (89%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (90%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (91%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (91%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (91%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (92%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (92%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (93%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (93%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (93%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (93%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001007 (98%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR001791 (80%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR012419 (11%)\n",
        "IPR000885 (100%);IPR008160 (100%);IPR013320 (100%)\n",
        "IPR000885 (77%);IPR008160 (77%);IPR003848 (19%)\n",
        "IPR000885 (95%);IPR001007 (95%);IPR008160 (95%)\n",
        "IPR001007 (100%);IPR008160 (100%);IPR000885 (67%)\n",
        "IPR001073 (100%);IPR008160 (100%);IPR008983 (100%)\n",
        "IPR001098 (33%);IPR002298 (33%);IPR002421 (33%)\n",
        "IPR001916 (81%);IPR023346 (81%);IPR000974 (80%)\n",
        "IPR002035 (100%);IPR002223 (100%);IPR003961 (100%)\n",
        "IPR002035 (100%);IPR003961 (100%);IPR013320 (100%)\n",
        "IPR002035 (100%);IPR003961 (100%);IPR013783 (100%)\n",
        "IPR002035 (100%);IPR008160 (100%);IPR013320 (100%)\n",
        "IPR002035 (100%);IPR008160 (100%);IPR036465 (100%)\n",
        "IPR002035 (100%);IPR008160 (100%);IPR036465 (100%)\n",
        "IPR002035 (100%);IPR008160 (100%);IPR036465 (100%)\n",
        "IPR002035 (100%);IPR008160 (100%);IPR036465 (100%)\n",
        "IPR002035 (100%);IPR008160 (100%);IPR036465 (100%)\n",
        "IPR002035 (100%);IPR008160 (100%);IPR036465 (100%)\n",
        "IPR002035 (100%);IPR036465 (100%);IPR041900 (99%)\n",
        "IPR003054 (100%);IPR018039 (100%);IPR032444 (100%)\n",
        "IPR008160 (100%)\n",
        "IPR008160 (100%)\n",
        "IPR008160 (100%)\n",
        "IPR008160 (100%)\n",
        "IPR008160 (100%)\n",
        "IPR008160 (100%)\n",
        "IPR008160 (100%)\n",
        "IPR008160 (100%);IPR000885 (100%);IPR001007 (58%)\n",
        "IPR008160 (100%);IPR000885 (14%);IPR001007 (12%)\n",
        "IPR008160 (100%);IPR000885 (35%);IPR013320 (19%)\n",
        "IPR008160 (100%);IPR000885 (50%)\n",
        "IPR008160 (100%);IPR000885 (50%)\n",
        "IPR008160 (100%);IPR000885 (50%);IPR001007 (50%)\n",
        "IPR008160 (100%);IPR000885 (50%);IPR001007 (50%)\n",
        "IPR008160 (100%);IPR000885 (55%);IPR001007 (52%)\n",
        "IPR008160 (100%);IPR000885 (62%);IPR001007 (45%)\n",
        "IPR008160 (100%);IPR000885 (67%);IPR001007 (67%)\n",
        "IPR008160 (100%);IPR000885 (67%);IPR001007 (67%)\n",
        "IPR008160 (100%);IPR000885 (67%);IPR001007 (67%)\n",
        "IPR008160 (100%);IPR000885 (67%);IPR001007 (67%)\n",
        "IPR008160 (100%);IPR000885 (68%);IPR001007 (52%)\n",
        "IPR008160 (100%);IPR000885 (69%);IPR001007 (69%)\n",
        "IPR008160 (100%);IPR000885 (71%);IPR001007 (71%)\n",
        "IPR008160 (100%);IPR000885 (75%);IPR001007 (75%)\n",
        "IPR008160 (100%);IPR000885 (76%);IPR001007 (73%)\n",
        "IPR008160 (100%);IPR000885 (76%);IPR001007 (73%)\n",
        "IPR008160 (100%);IPR000885 (80%);IPR001007 (60%)\n",
        "IPR008160 (100%);IPR000885 (80%);IPR001007 (64%)\n",
        "IPR008160 (100%);IPR000885 (81%);IPR001007 (79%)\n",
        "IPR008160 (100%);IPR000885 (83%)\n",
        "IPR008160 (100%);IPR000885 (83%);IPR001007 (67%)\n",
        "IPR008160 (100%);IPR000885 (84%);IPR001007 (83%)\n",
        "IPR008160 (100%);IPR000885 (85%);IPR001007 (81%)\n",
        "IPR008160 (100%);IPR000885 (86%);IPR001007 (47%)\n",
        "IPR008160 (100%);IPR000885 (86%);IPR001007 (83%)\n",
        "IPR008160 (100%);IPR000885 (86%);IPR001007 (84%)\n",
        "IPR008160 (100%);IPR000885 (86%);IPR001007 (86%)\n",
        "IPR008160 (100%);IPR000885 (87%);IPR001007 (85%)\n",
        "IPR008160 (100%);IPR000885 (88%)\n",
        "IPR008160 (100%);IPR000885 (88%);IPR001007 (63%)\n",
        "IPR008160 (100%);IPR000885 (88%);IPR001007 (83%)\n",
        "IPR008160 (100%);IPR000885 (88%);IPR001007 (85%)\n",
        "IPR008160 (100%);IPR000885 (88%);IPR001007 (85%)\n",
        "IPR008160 (100%);IPR000885 (89%)\n",
        "IPR008160 (100%);IPR000885 (89%);IPR001007 (77%)\n",
        "IPR008160 (100%);IPR000885 (89%);IPR001007 (83%)\n",
        "IPR008160 (100%);IPR000885 (89%);IPR001007 (83%)\n",
        "IPR008160 (100%);IPR000885 (89%);IPR001007 (84%)\n",
        "IPR008160 (100%);IPR000885 (90%);IPR001007 (44%)\n",
        "IPR008160 (100%);IPR000885 (90%);IPR001007 (84%)\n",
        "IPR008160 (100%);IPR000885 (90%);IPR001007 (86%)\n",
        "IPR008160 (100%);IPR000885 (90%);IPR001007 (90%)\n",
        "IPR008160 (100%);IPR000885 (90%);IPR001791 (80%)\n",
        "IPR008160 (100%);IPR000885 (91%);IPR001007 (79%)\n",
        "IPR008160 (100%);IPR000885 (91%);IPR001007 (82%)\n",
        "IPR008160 (100%);IPR000885 (91%);IPR001007 (83%)\n",
        "IPR008160 (100%);IPR000885 (91%);IPR001007 (83%)\n",
        "IPR008160 (100%);IPR000885 (91%);IPR001007 (86%)\n",
        "IPR008160 (100%);IPR000885 (91%);IPR001007 (88%)\n",
        "IPR008160 (100%);IPR000885 (92%)\n",
        "IPR008160 (100%);IPR000885 (92%)\n",
        "IPR008160 (100%);IPR000885 (92%);IPR001007 (24%)\n",
        "IPR008160 (100%);IPR000885 (92%);IPR001007 (35%)\n",
        "IPR008160 (100%);IPR000885 (92%);IPR001007 (82%)\n",
        "IPR008160 (100%);IPR000885 (92%);IPR001007 (92%)\n",
        "IPR008160 (100%);IPR000885 (92%);IPR001007 (92%)\n",
        "IPR008160 (100%);IPR000885 (92%);IPR012419 (1%)\n",
        "IPR008160 (100%);IPR000885 (92%);IPR012419 (1%)\n",
        "IPR008160 (100%);IPR000885 (93%)\n",
        "IPR008160 (100%);IPR000885 (93%)\n",
        "IPR008160 (100%);IPR000885 (93%);IPR001007 (36%)\n",
        "IPR008160 (100%);IPR000885 (93%);IPR001007 (89%)\n",
        "IPR008160 (100%);IPR000885 (93%);IPR001007 (93%)\n",
        "IPR008160 (100%);IPR000885 (94%);IPR001007 (29%)\n",
        "IPR008160 (100%);IPR000885 (94%);IPR001007 (48%)\n",
        "IPR008160 (100%);IPR000885 (94%);IPR001007 (49%)\n",
        "IPR008160 (100%);IPR000885 (94%);IPR001007 (62%)\n",
        "IPR008160 (100%);IPR000885 (94%);IPR001007 (79%)\n",
        "IPR008160 (100%);IPR000885 (94%);IPR001007 (89%)\n",
        "IPR008160 (100%);IPR000885 (94%);IPR001007 (90%)\n",
        "IPR008160 (100%);IPR000885 (94%);IPR012419 (0%)\n",
        "IPR008160 (100%);IPR000885 (94%);IPR012419 (0%)\n",
        "IPR008160 (100%);IPR000885 (94%);IPR012419 (0%)\n",
        "IPR008160 (100%);IPR000885 (94%);IPR012419 (2%)\n",
        "IPR008160 (100%);IPR000885 (94%);IPR013320 (87%)\n",
        "IPR008160 (100%);IPR000885 (94%);IPR013320 (88%)\n",
        "IPR008160 (100%);IPR000885 (95%)\n",
        "IPR008160 (100%);IPR000885 (95%)\n",
        "IPR008160 (100%);IPR000885 (95%)\n",
        "IPR008160 (100%);IPR000885 (95%)\n",
        "IPR008160 (100%);IPR000885 (95%)\n",
        "IPR008160 (100%);IPR000885 (95%)\n",
        "IPR008160 (100%);IPR000885 (95%);IPR001007 (82%)\n",
        "IPR008160 (100%);IPR000885 (95%);IPR001007 (88%)\n",
        "IPR008160 (100%);IPR000885 (95%);IPR013320 (91%)\n",
        "IPR008160 (100%);IPR000885 (96%)\n",
        "IPR008160 (100%);IPR000885 (96%)\n",
        "IPR008160 (100%);IPR000885 (96%)\n",
        "IPR008160 (100%);IPR000885 (96%);IPR001007 (22%)\n",
        "IPR008160 (100%);IPR000885 (96%);IPR001007 (52%)\n",
        "IPR008160 (100%);IPR000885 (96%);IPR001007 (52%)\n",
        "IPR008160 (100%);IPR000885 (96%);IPR001007 (68%)\n",
        "IPR008160 (100%);IPR000885 (96%);IPR001007 (74%)\n",
        "IPR008160 (100%);IPR000885 (96%);IPR001007 (77%)\n",
        "IPR008160 (100%);IPR000885 (96%);IPR001007 (78%)\n",
        "IPR008160 (100%);IPR000885 (96%);IPR001007 (89%)\n",
        "IPR008160 (100%);IPR000885 (96%);IPR001007 (90%)\n",
        "IPR008160 (100%);IPR000885 (96%);IPR001007 (91%)\n",
        "IPR008160 (100%);IPR000885 (96%);IPR001007 (95%)\n",
        "IPR008160 (100%);IPR000885 (96%);IPR012419 (3%)\n",
        "IPR008160 (100%);IPR000885 (97%)\n",
        "IPR008160 (100%);IPR000885 (97%)\n",
        "IPR008160 (100%);IPR000885 (97%);IPR001007 (36%)\n",
        "IPR008160 (100%);IPR000885 (97%);IPR001007 (87%)\n",
        "IPR008160 (100%);IPR000885 (97%);IPR001007 (91%)\n",
        "IPR008160 (100%);IPR000885 (97%);IPR001007 (91%)\n",
        "IPR008160 (100%);IPR000885 (97%);IPR001007 (93%)\n",
        "IPR008160 (100%);IPR000885 (97%);IPR001007 (96%)\n",
        "IPR008160 (100%);IPR000885 (97%);IPR001007 (97%)\n",
        "IPR008160 (100%);IPR000885 (97%);IPR048287 (93%)\n",
        "IPR008160 (100%);IPR000885 (98%)\n",
        "IPR008160 (100%);IPR000885 (98%)\n",
        "IPR008160 (100%);IPR000885 (98%)\n",
        "IPR008160 (100%);IPR000885 (98%);IPR001007 (17%)\n",
        "IPR008160 (100%);IPR000885 (98%);IPR001007 (45%)\n",
        "IPR008160 (100%);IPR000885 (98%);IPR001007 (61%)\n",
        "IPR008160 (100%);IPR000885 (98%);IPR001007 (63%)\n",
        "IPR008160 (100%);IPR000885 (98%);IPR001007 (66%)\n",
        "IPR008160 (100%);IPR000885 (98%);IPR001007 (73%)\n",
        "IPR008160 (100%);IPR000885 (98%);IPR001007 (75%)\n",
        "IPR008160 (100%);IPR000885 (98%);IPR001007 (78%)\n",
        "IPR008160 (100%);IPR000885 (98%);IPR001007 (91%)\n",
        "IPR008160 (100%);IPR000885 (98%);IPR001007 (93%)\n",
        "IPR008160 (100%);IPR000885 (98%);IPR001007 (93%)\n",
        "IPR008160 (100%);IPR000885 (98%);IPR001007 (93%)\n",
        "IPR008160 (100%);IPR000885 (98%);IPR001007 (94%)\n",
        "IPR008160 (100%);IPR000885 (98%);IPR001007 (97%)\n",
        "IPR008160 (100%);IPR000885 (98%);IPR012419 (1%)\n",
        "IPR008160 (100%);IPR000885 (98%);IPR013320 (89%)\n",
        "IPR008160 (100%);IPR000885 (98%);IPR013320 (90%)\n",
        "IPR008160 (100%);IPR000885 (99%)\n",
        "IPR008160 (100%);IPR000885 (99%)\n",
        "IPR008160 (100%);IPR000885 (99%)\n",
        "IPR008160 (100%);IPR000885 (99%);IPR001007 (56%)\n",
        "IPR008160 (100%);IPR000885 (99%);IPR001007 (58%)\n",
        "IPR008160 (100%);IPR000885 (99%);IPR001007 (59%)\n",
        "IPR008160 (100%);IPR000885 (99%);IPR001007 (60%)\n",
        "IPR008160 (100%);IPR000885 (99%);IPR001007 (79%)\n",
        "IPR008160 (100%);IPR000885 (99%);IPR001007 (81%)\n",
        "IPR008160 (100%);IPR000885 (99%);IPR001007 (81%)\n",
        "IPR008160 (100%);IPR000885 (99%);IPR001007 (90%)\n",
        "IPR008160 (100%);IPR000885 (99%);IPR001007 (91%)\n",
        "IPR008160 (100%);IPR000885 (99%);IPR001007 (92%)\n",
        "IPR008160 (100%);IPR000885 (99%);IPR012419 (2%)\n",
        "IPR008160 (100%);IPR000885 (99%);IPR013320 (91%)\n",
        "IPR008160 (100%);IPR001007 (66%);IPR000885 (63%)\n",
        "IPR008160 (100%);IPR001007 (92%);IPR000885 (90%)\n",
        "IPR008160 (100%);IPR001007 (98%);IPR000885 (95%)\n",
        "IPR008160 (100%);IPR002035 (60%);IPR036465 (60%)\n",
        "IPR008160 (100%);IPR002035 (85%);IPR003961 (85%)\n",
        "IPR008160 (100%);IPR002035 (94%);IPR002223 (94%)\n",
        "IPR008160 (100%);IPR013320 (95%);IPR048287 (94%)\n",
        "IPR008160 (100%);IPR013320 (96%);IPR048287 (96%)\n",
        "IPR008160 (100%);IPR013320 (96%);IPR048287 (96%)\n",
        "IPR008160 (100%);IPR013320 (96%);IPR048287 (96%)\n",
        "IPR008160 (100%);IPR016187 (80%);IPR001304 (40%)\n",
        "IPR008160 (17%);IPR029044 (12%);IPR003329 (11%)\n",
        "IPR008160 (19%);IPR019018 (13%);IPR037789 (13%)\n",
        "IPR008160 (20%);IPR027417 (7%);IPR001734 (5%)\n",
        "IPR008160 (22%);IPR002125 (10%);IPR016193 (10%)\n",
        "IPR008160 (27%);IPR002035 (17%);IPR036465 (17%)\n",
        "IPR008160 (29%);IPR000885 (16%);IPR009075 (13%)\n",
        "IPR008160 (32%);IPR000885 (26%);IPR001007 (22%)\n",
        "IPR008160 (32%);IPR000885 (30%);IPR001007 (24%)\n",
        "IPR008160 (34%);IPR000885 (11%);IPR036465 (11%)\n",
        "IPR008160 (37%);IPR000885 (33%);IPR001245 (20%)\n",
        "IPR008160 (37%);IPR013783 (29%);IPR002035 (29%)\n",
        "IPR008160 (38%);IPR001036 (30%);IPR004764 (30%)\n",
        "IPR008160 (38%);IPR016187 (15%);IPR002035 (14%)\n",
        "IPR008160 (44%);IPR036465 (32%);IPR002035 (32%)\n",
        "IPR008160 (52%);IPR000885 (32%);IPR001007 (25%)\n",
        "IPR008160 (53%);IPR048287 (36%);IPR013320 (36%)\n",
        "IPR008160 (6%);IPR027417 (5%);IPR013783 (3%)\n",
        "IPR008160 (67%);IPR000885 (56%);IPR001298 (11%)\n",
        "IPR008160 (71%);IPR000885 (55%);IPR001007 (39%)\n",
        "IPR008160 (74%);IPR000885 (66%);IPR008610 (3%)\n",
        "IPR008160 (76%);IPR000885 (71%);IPR001007 (51%)\n",
        "IPR008160 (78%);IPR000885 (73%);IPR001007 (69%)\n",
        "IPR008160 (81%);IPR000885 (70%);IPR013320 (58%)\n",
        "IPR008160 (82%);IPR000885 (61%);IPR001007 (34%)\n",
        "IPR008160 (83%);IPR000885 (65%);IPR013320 (57%)\n",
        "IPR008160 (86%);IPR000885 (38%);IPR001007 (32%)\n",
        "IPR008160 (87%);IPR000885 (28%);IPR001007 (22%)\n",
        "IPR008160 (87%);IPR000885 (57%);IPR001007 (41%)\n",
        "IPR008160 (89%);IPR000885 (39%);IPR013320 (33%)\n",
        "IPR008160 (89%);IPR002035 (25%);IPR036465 (25%)\n",
        "IPR008160 (94%);IPR000885 (63%);IPR001007 (38%)\n",
        "IPR008160 (94%);IPR000885 (71%);IPR001007 (65%)\n",
        "IPR008160 (94%);IPR000885 (81%);IPR005546 (6%)\n",
        "IPR008160 (95%);IPR000885 (90%);IPR001007 (80%)\n",
        "IPR008160 (95%);IPR000885 (91%);IPR001007 (72%)\n",
        "IPR008160 (95%);IPR001442 (23%);IPR016187 (23%)\n",
        "IPR008160 (96%);IPR000885 (53%);IPR001007 (45%)\n",
        "IPR008160 (96%);IPR019931 (42%);IPR019950 (42%)\n",
        "IPR008160 (98%);IPR000885 (89%);IPR048287 (41%)\n",
        "IPR008160 (98%);IPR000885 (96%);IPR001007 (89%)\n",
        "IPR008160 (99%);IPR000885 (85%);IPR001007 (61%)\n",
        "IPR008160 (99%);IPR000885 (87%);IPR001007 (81%)\n",
        "IPR008160 (99%);IPR000885 (90%);IPR013320 (64%)\n",
        "IPR008160 (99%);IPR000885 (94%);IPR001007 (84%)\n",
        "IPR008160 (99%);IPR000885 (94%);IPR001007 (84%)\n",
        "IPR008160 (99%);IPR000885 (95%);IPR001007 (89%)\n",
        "IPR008160 (99%);IPR000885 (99%);IPR013320 (86%)\n",
        "IPR008160 (99%);IPR001007 (96%);IPR000885 (95%)\n",
        "IPR008160 (99%);IPR002035 (96%);IPR036465 (96%)\n",
        "IPR013783 (39%);IPR008902 (38%);IPR013737 (38%)\n",
        "IPR027417 (7%);IPR017946 (5%);IPR030395 (5%)\n",
        "\"\"\"\n",
        "\n",
        "# Split the input data into lines, then process each line\n",
        "lines = input_data.strip().split('\\n')\n",
        "\n",
        "# Initialize a set to hold unique InterPro IDs with 100% match\n",
        "interpro_ids_100 = set()\n",
        "\n",
        "for line in lines:\n",
        "    parts = line.split(';')\n",
        "    for part in parts:\n",
        "        if '(100%)' in part:\n",
        "            # Extract the InterPro ID\n",
        "            interpro_id = part.split(' ')[0]\n",
        "            interpro_ids_100.add(interpro_id)\n",
        "\n",
        "# Convert the set to a list if needed or directly iterate over the set\n",
        "interpro_ids_100_list = list(interpro_ids_100)\n",
        "print(interpro_ids_100_list)\n"
      ],
      "metadata": {
        "id": "gcgPh4HiMY0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Query Interpro\n",
        "for interpro_id in interpro_ids_100_list:\n",
        "    data = query_interpro(interpro_id)\n",
        "    if data:\n",
        "        # Example of how you might extract protein details\n",
        "        # The actual keys and structure will depend on the API response\n",
        "        for entry in data.get('entries', []):\n",
        "            for protein in entry.get('proteins', []):\n",
        "                protein_id = protein.get('id')\n",
        "                sequence = protein.get('sequence', {}).get('value')\n",
        "                taxonomy = protein.get('taxonomy', {}).get('scientificName')\n",
        "                print(protein_id, sequence, taxonomy)"
      ],
      "metadata": {
        "id": "KF2GKCFhOUvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "KB8cidyIgoFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proteins Constrast  Functions"
      ],
      "metadata": {
        "id": "66KHMj35mwMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function: `get_complement_proteins`\n",
        "This function calculates the complementary proteins for a given protein within a list of proteins, based on a specified group of proteins.\n",
        "### Function: `get_info_dic`\n",
        "This function parses a file to extract protein, peptide, and modification information, organizing it into a nested dictionary structure.\n",
        "\n",
        "### Function: `reformate_dic`\n",
        "This function iterates over a dictionary, presumably structured with proteins as keys and another dictionary as values, where the inner dictionary has tuples of peptide and modification as keys. It restructures this into a dictionary where proteins are keys, leading to peptides, which map to a list of tuples containing modification and the original details.\n",
        "\n",
        "### Function: `get_all_pros_sites_peps`\n",
        "This function appears to collect all proteins, sites, and peptides from a given dictionary, likely for further analysis or reporting. The function's specifics and its intended output format are deduced from the provided code snippet.\n",
        "\n",
        "### Function: `compare_results`\n",
        "This function is designed to compare and analyze the differences between two datasets or experimental results. The specifics of the comparison criteria and the expected format of the inputs and outputs are not provided in the snippet.\n",
        "\n",
        "### Function: `write_dic2_file`\n",
        "This function writes the content of a dictionary to a file, organizing the data in a specific format that would presumably be useful for downstream analysis or reporting.\n"
      ],
      "metadata": {
        "id": "1frnVuPTmmhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_complement_proteins(protein_list, pro, group_pro):\n",
        "    \"\"\"\n",
        "    Calculate complementary proteins for a given protein in a list, based on a group of proteins.\n",
        "\n",
        "    Parameters:\n",
        "    - protein_list (list): A list of proteins potentially related to a peptide.\n",
        "    - pro (str): The target protein for which complementary proteins are sought.\n",
        "    - group_pro (list): A group of proteins considered relevant for the analysis.\n",
        "\n",
        "    Returns:\n",
        "    - str: A string of complementary proteins separated by slashes (\"/\").\n",
        "    \"\"\"\n",
        "    if len(protein_list) == 1 and protein_list[0] == pro:\n",
        "        return \"\"\n",
        "    else:\n",
        "        group_set = set(group_pro)  # Convert group of proteins to a set for efficient lookup\n",
        "        pep_related_pro = set(protein_list)  # Convert list of potentially related proteins to a set\n",
        "        target_pro_set = {pro}  # Convert target protein to a set for operations\n",
        "        complement_pros = pep_related_pro - target_pro_set & group_set  # Calculate complementary proteins\n",
        "        return \"/\".join(list(complement_pros))\n",
        "\n",
        "\n",
        "def get_info_dic(fl_path):\n",
        "    \"\"\"\n",
        "    Parse a file to extract and organize protein, peptide, and modification information.\n",
        "\n",
        "    Parameters:\n",
        "    - fl_path (str): Path to the file containing protein and peptide information.\n",
        "\n",
        "    Returns:\n",
        "    - dict: A dictionary with proteins as keys and details of associated peptides and modifications as values.\n",
        "    \"\"\"\n",
        "    rep_dic = {}\n",
        "    with open(fl_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    i = 0\n",
        "    while i < len(lines) - 5:\n",
        "        if lines[i].startswith(\"-----\"):\n",
        "            break\n",
        "        else:\n",
        "            linelist = lines[i].strip().split(\"\\t\")\n",
        "            if not linelist[0].isdigit():\n",
        "                i += 1\n",
        "                continue\n",
        "\n",
        "            group_pro = [linelist[1]]\n",
        "            i += 1\n",
        "            while i < len(lines) - 5:\n",
        "                sub_list = lines[i].strip().split(\"\\t\")\n",
        "                if sub_list[2].isdigit():\n",
        "                    break\n",
        "                else:\n",
        "                    group_pro.append(sub_list[2])\n",
        "                    i += 1\n",
        "\n",
        "            while i < len(lines) - 5:\n",
        "                pep_info_list = lines[i].strip().split(\"\\t\")\n",
        "                if \"-----\" in lines[i]:\n",
        "                    break\n",
        "                elif pep_info_list[0].isdigit():\n",
        "                    i += 1\n",
        "                    continue\n",
        "                else:\n",
        "                    # Extract and process peptide information\n",
        "                    pep = pep_info_list[3]\n",
        "                    mod = pep_info_list[8]\n",
        "                    pros = pep_info_list[10]\n",
        "                    spec = pep_info_list[-1]\n",
        "                    pro_list = pros[:-1].split(\"/\")\n",
        "                    best_score = pep_info_list[7]\n",
        "                    is_unique = \"not unique\" if len(pro_list) > 1 else \"is unique\"\n",
        "                    for pro in pro_list:\n",
        "                        if pro in group_pro:\n",
        "                            comple_pros = get_complement_proteins(pro_list, pro, group_pro)\n",
        "                            if pro not in rep_dic:\n",
        "                                rep_dic[pro] = {}\n",
        "                            rep_dic[pro][(pep, mod)] = [spec, best_score, is_unique, comple_pros]\n",
        "                    i += 1\n",
        "    return rep_dic\n",
        "\n",
        "def reformat_dic(info_dic):\n",
        "    \"\"\"\n",
        "    Reformat the given dictionary to a specific structure.\n",
        "\n",
        "    Parameters:\n",
        "    - info_dic (dict): The dictionary to reformat, assumed to contain protein-related information.\n",
        "\n",
        "    Returns:\n",
        "    - dict: The reformatted dictionary.\n",
        "    \"\"\"\n",
        "    new_dic = {}\n",
        "    for pro, pep_info in info_dic.items():\n",
        "        for pep_mod, details in pep_info.items():\n",
        "            pep, mod = pep_mod\n",
        "            if pro not in new_dic:\n",
        "                new_dic[pro] = {}\n",
        "            if pep not in new_dic[pro]:\n",
        "                new_dic[pro][pep] = []\n",
        "            new_dic[pro][pep].append((mod, details))\n",
        "    return new_dic\n",
        "\n",
        "def get_all_pros_sites_peps(info_dic):\n",
        "    \"\"\"\n",
        "    Extract all proteins, sites, and peptides from the given dictionary.\n",
        "\n",
        "    Parameters:\n",
        "    - info_dic (dict): The dictionary containing protein, peptide, and site information.\n",
        "\n",
        "    Returns:\n",
        "    - list: A list of tuples, each containing a protein, site, and peptide.\n",
        "    \"\"\"\n",
        "    all_list = []\n",
        "    for pro, pep_details in info_dic.items():\n",
        "        for pep, mods_details in pep_details.items():\n",
        "            for mod, details in mods_details:\n",
        "                all_list.append((pro, mod, pep))\n",
        "    return all_list\n",
        "\n",
        "def compare_results(dic1, dic2):\n",
        "    \"\"\"\n",
        "    Compare and analyze the differences between two dictionaries.\n",
        "\n",
        "    Parameters:\n",
        "    - dic1 (dict): The first dictionary for comparison.\n",
        "    - dic2 (dict): The second dictionary for comparison.\n",
        "\n",
        "    Returns:\n",
        "    - dict: A dictionary containing the results of the comparison.\n",
        "    \"\"\"\n",
        "    result_dic = {}\n",
        "    # Implementation of comparison logic would go here.\n",
        "    # This would likely involve iterating over the keys and values of both dictionaries,\n",
        "    # comparing their contents, and storing the differences in result_dic.\n",
        "    return result_dic\n",
        "\n",
        "def write_dic2_file(dic, file_path):\n",
        "    \"\"\"\n",
        "    Write the content of a dictionary to a file in a specified format.\n",
        "\n",
        "    Parameters:\n",
        "    - dic (dict): The dictionary whose content is to be written.\n",
        "    - file_path (str): The path of the file where the dictionary content will be written.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    with open(file_path, 'w') as f:\n",
        "        for key, value in dic.items():\n",
        "            f.write(f\"{key}: {value}\\n\")\n"
      ],
      "metadata": {
        "id": "ng2wqoDomhzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PTM Functions\n",
        "### Function: `get_modi_info`\n",
        "\n",
        "This function retrieves information about specific modifications from a list of protein data.\n",
        "\n",
        "### Function: `get_complement_proteins`\n",
        "\n",
        "This function generates a string of proteins, excluding the protein at index `i`.\n",
        "\n",
        "### Function: `get_info_dic`\n",
        "\n",
        "This function processes a file to extract and organize information about proteins, peptides, modifications, and other related data, based on a specific modification interest.\n",
        "\n",
        "### Function: `reformat_dic`\n",
        "\n",
        "This function reorganizes the dictionary structure obtained from `get_info_dic` for further analysis or reporting.\n",
        "\n",
        "unctions `analyze_site`, `update_protein_metrics`, and `pro_metrics_summary` would need to be defined to handle specific tasks within `reformat_dic`, following the principle of breaking down complex tasks into smaller, manageable functions.\n",
        "\n",
        "### Function: `get_all_pros_sites_peps`\n",
        "\n",
        "This function compiles a comprehensive list of all proteins, sites, and peptides from the given dictionary.\n",
        "\n",
        "\n",
        "### Function: `compare_results`\n",
        "\n",
        "This function compares the results across different datasets or experimental conditions.\n",
        "\n",
        "### Function: `compare_structured_data`\n",
        "\n",
        "The function `compare_structured_data` needs to be implemented to perform the actual comparison of structured data, identifying common and unique entries across datasets. This design aims to maintain a clear separation of concerns, with each function responsible for a distinct aspect of the data processing pipeline.\n",
        "\n"
      ],
      "metadata": {
        "id": "6iLAnh9L9hI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pFind_PTM_contrast functions\n",
        "def get_modi_info(line_list, mod_target):\n",
        "    \"\"\"\n",
        "    Extracts modification information for a given modification target from a list.\n",
        "\n",
        "    Parameters:\n",
        "    - line_list (list): The list containing protein data.\n",
        "    - mod_target (str): The target modification to search for.\n",
        "\n",
        "    Returns:\n",
        "    - list: A list of lists containing information about the target modification.\n",
        "    \"\"\"\n",
        "    proteins = line_list[10]\n",
        "    modifications = line_list[8]\n",
        "    peptide = line_list[3]\n",
        "    protein_list = proteins[:-1].split('/')\n",
        "    peptide_position_list = line_list[11][:-1].split('/')\n",
        "    modification_list = modifications[:-1].split(\";\")\n",
        "    spectrum_number = line_list[-1]\n",
        "    score = line_list[7]\n",
        "    info_list = []\n",
        "\n",
        "    for mod_info in modification_list:\n",
        "        modification_position, modification_name = mod_info.split(',')\n",
        "        if modification_name == mod_target:\n",
        "            protein_position_list = []\n",
        "            for i, protein in enumerate(protein_list):\n",
        "                peptide_position = int(peptide_position_list[i].split(',')[0])\n",
        "                modification_position_int = peptide_position + int(modification_position)\n",
        "                protein_position = protein + \"[\" + str(modification_position_int) + \"]\"\n",
        "                protein_position_list.append(protein_position)\n",
        "            protein_positions = \"/\".join(protein_position_list) + \"/\"\n",
        "            info_list.append([proteins, protein_positions, peptide, modifications, score, spectrum_number])\n",
        "\n",
        "    return info_list\n",
        "\n",
        "def get_complement_proteins(protein_list, i):\n",
        "    \"\"\"\n",
        "    Generates a string of proteins excluding the one at the specified index.\n",
        "\n",
        "    Parameters:\n",
        "    - protein_list (list): The list of proteins.\n",
        "    - i (int): The index of the protein to exclude.\n",
        "\n",
        "    Returns:\n",
        "    - str: A string of the remaining proteins joined by \"/\".\n",
        "    \"\"\"\n",
        "    copy_list = copy.deepcopy(protein_list)\n",
        "    del copy_list[i]\n",
        "    return \"\" if not copy_list else \"/\".join(copy_list)"
      ],
      "metadata": {
        "id": "4EVS5OXJ9V3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_info_dic(file_path, modify):\n",
        "    \"\"\"\n",
        "    Extracts and organizes protein and peptide information from a file, based on a specific modification.\n",
        "\n",
        "    Parameters:\n",
        "    - file_path (str): The path to the input file.\n",
        "    - modify (str): The modification to filter the data by.\n",
        "\n",
        "    Returns:\n",
        "    - dict: A dictionary with proteins as keys and their site-specific information as values.\n",
        "    \"\"\"\n",
        "    uni_dic = {}\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    for line in lines:\n",
        "        if modify in line:\n",
        "            line_list = line.rstrip(\"\\n\").split(\"\\t\")\n",
        "            pro_sites_info = get_modi_info(line_list, modify)\n",
        "\n",
        "            for pro_site in pro_sites_info:\n",
        "                pros, pro_pos, pep, mods, score, spec_num = pro_site\n",
        "                protein_list = pros[:-1].split(\"/\")\n",
        "                is_unique = \"unique\" if len(protein_list) == 1 else \"not unique\"\n",
        "                pro_pos_list = pro_pos[:-1].split('/')\n",
        "\n",
        "                for i, protein in enumerate(protein_list):\n",
        "                    pep_info_list = [pep, mods, score, spec_num, is_unique]\n",
        "                    complem_proteins = get_complement_proteins(protein_list, i)\n",
        "                    pep_info_list.append(complem_proteins)\n",
        "                    protein_pos = pro_pos_list[i]\n",
        "\n",
        "                    if protein not in uni_dic:\n",
        "                        uni_dic[protein] = {}\n",
        "                    uni_dic[protein].setdefault(protein_pos, []).append(pep_info_list)\n",
        "\n",
        "    return uni_dic\n",
        "\n",
        "def reformat_dic(uni_dic):\n",
        "    \"\"\"\n",
        "    Reorganizes the dictionary structure for protein and peptide information.\n",
        "\n",
        "    Parameters:\n",
        "    - uni_dic (dict): The initial dictionary with unorganized protein information.\n",
        "\n",
        "    Returns:\n",
        "    - dict: A reorganized dictionary with detailed protein and site information.\n",
        "    \"\"\"\n",
        "    re_uni_dic = {}\n",
        "    for protein, sites_info in uni_dic.items():\n",
        "        pro_metrics = {\"m_num\": 0, \"best_score\": float('inf'), \"p_num\": 0, \"site_num\": 0, \"uni_pep_pro\": \"no unique peptides\"}\n",
        "        pro_sites_dic = {}\n",
        "\n",
        "        for site, peptides in sites_info.items():\n",
        "            site_data = analyze_site(peptides)\n",
        "            update_protein_metrics(pro_metrics, site_data)\n",
        "\n",
        "            pro_sites_dic[site] = site_data\n",
        "\n",
        "        re_uni_dic[protein] = [pro_metrics_summary(pro_metrics), pro_sites_dic]\n",
        "\n",
        "    return re_uni_dic\n",
        "\n",
        "def get_all_pros_sites_peps(total_dic):\n",
        "    \"\"\"\n",
        "    Compiles information on all proteins, their sites, and associated peptides.\n",
        "\n",
        "    Parameters:\n",
        "    - total_dic (dict): The dictionary containing detailed protein information.\n",
        "\n",
        "    Returns:\n",
        "    - dict: A structured dictionary with comprehensive information on proteins, sites, and peptides.\n",
        "    \"\"\"\n",
        "    structured_dic = {}\n",
        "    for sample, sample_data in total_dic.items():\n",
        "        for protein, sites_info in sample_data.items():\n",
        "            if protein not in structured_dic:\n",
        "                structured_dic[protein] = {\"sites\": {}}\n",
        "\n",
        "            for site, site_info in sites_info[\"sites\"].items():\n",
        "                structured_dic[protein][\"sites\"].setdefault(site, {\"peptides\": []})\n",
        "                peptides = structured_dic[protein][\"sites\"][site][\"peptides\"]\n",
        "\n",
        "                for peptide_info in site_info[\"peptides\"]:\n",
        "                    peptides.append(peptide_info)\n",
        "\n",
        "    return structured_dic\n",
        "\n",
        "def compare_results(total_dic):\n",
        "    \"\"\"\n",
        "    Compares protein, site, and peptide information across different datasets.\n",
        "\n",
        "    Parameters:\n",
        "    - total_dic (dict): A dictionary containing protein information from various datasets.\n",
        "\n",
        "    Returns:\n",
        "    - dict: A dictionary highlighting differences or similarities across datasets.\n",
        "    \"\"\"\n",
        "    if len(total_dic) == 1:\n",
        "        return next(iter(total_dic.values()))\n",
        "\n",
        "    structured_dic = get_all_pros_sites_peps(total_dic)\n",
        "    compare_structured_data(structured_dic, total_dic)\n",
        "\n",
        "\n",
        "    return structured_dic\n",
        "\n",
        "\n",
        "def write_dic2_file(final_dic, sp_list, w_name, base_path):\n",
        "    \"\"\"\n",
        "    Writes the dictionary containing protein, site, and peptide information to a file.\n",
        "\n",
        "    The output file is structured with headers and subheaders to organize the information\n",
        "    across different samples, including details about proteins, sites, peptides, and modifications.\n",
        "\n",
        "    Parameters:\n",
        "    - final_dic (dict): The dictionary containing the data to be written to the file.\n",
        "    - sp_list (list): A list of sample identifiers.\n",
        "    - w_name (str): The name of the output file.\n",
        "    - base_path (str): The base path where the output file will be saved.\n",
        "\n",
        "    This function creates a file in the specified base path and writes the contents of `final_dic`\n",
        "    into it in a tab-separated format. It organizes the data with headers for easy understanding.\n",
        "    \"\"\"\n",
        "    # Define the full path for the output file\n",
        "    output_file_path = os.path.join(base_path, w_name)\n",
        "\n",
        "    # Open the file for writing\n",
        "    with open(output_file_path, 'w') as b:\n",
        "        # Write the headers\n",
        "        line1_list = [\"\"] * 4\n",
        "        line1_list.extend([sp + \"\\t\" * 3 for sp in sp_list])\n",
        "        b.write(\"\\t\".join(line1_list) + \"\\n\")\n",
        "\n",
        "        line2_list = [\"Protein\", \"\", \"\", \"\"]\n",
        "        line2_list.extend([\"Total_site_num@pro\", \"Total_pep_num@pro\", \"Total_spec_num@pro\", \"have unique peptides?\"] * len(sp_list))\n",
        "        b.write(\"\\t\".join(line2_list) + \"\\n\")\n",
        "\n",
        "        line3_list = [\"\", \"site\", \"\", \"\"]\n",
        "        line3_list.extend([\"Total_pep_num@site(Total_unique_pep_num@site)\", \"Total_spec_num@site(Total_unique_spec_num@site)\", \"best-score@site\", \"have unique peptides?\"] * len(sp_list))\n",
        "        b.write(\"\\t\".join(line3_list) + \"\\n\")\n",
        "\n",
        "        line4_list = [\"\", \"\", \"Peptide\", \"Modification\"]\n",
        "        line4_list.extend([\"Total_spec_num@pep\", \"shared proteins\", \"best-score@pep\", \"is unique?\"] * len(sp_list))\n",
        "        b.write(\"\\t\".join(line4_list) + \"\\n\")\n",
        "\n",
        "        # Write the data from the dictionary\n",
        "        for pro, (pro_info, sites_dic) in final_dic.items():\n",
        "            pro_wlist = [pro] + [\"\"] * 3 + pro_info\n",
        "            b.write(\"\\t\".join(map(str, pro_wlist)) + \"\\n\")\n",
        "            for site, (site_info, peps_dic) in sites_dic.items():\n",
        "                site_wlist = [\"\", site] + [\"\"] * 2 + site_info\n",
        "                b.write(\"\\t\".join(map(str, site_wlist)) + \"\\n\")\n",
        "                for (pep, mod), pep_info in peps_dic.items():\n",
        "                    pep_wlist = [\"\", \"\", pep, mod] + pep_info\n",
        "                    b.write(\"\\t\".join(map(str, pep_wlist)) + \"\\n\")\n"
      ],
      "metadata": {
        "id": "PqcOcvI4ASMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "WbqOWMb4iU41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ArijyQ5BmfaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pFind_protein_contrastfunctions\n",
        "\n",
        "BASE_PATH = f'/content/drive/MyDrive/Colab_Notebooks/NovorCloud/Dinosaur/{STUDY_NAME}/{PFIND_FOLDER}'\n",
        "output_name = \"pFind_protein_contrast_result.txt\" # important! the output file name"
      ],
      "metadata": {
        "id": "rSpoKxJpiePj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path PTM\n",
        "BASE_PATH = f'/content/drive/MyDrive/Colab_Notebooks/NovorCloud/Dinosaur/{STUDY_NAME}/{PFIND_FOLDER}'\n",
        "output_name = \"pFind_PTM_contrast_result.txt\" # important! the output file name\n",
        "modify = \"Oxidation[M]\" # target modification name"
      ],
      "metadata": {
        "id": "Xhrst_J4jKUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pFind_PTM_contrast\n",
        "def main():\n",
        "    total_dic = {}\n",
        "    for fl in os.listdir(BASE_PATH):\n",
        "        if fl.endswith(\".protein\"):\n",
        "            fl_path = os.path.join(BASE_PATH, fl)\n",
        "            fl_name = fl[:-8]\n",
        "            print(fl_path)\n",
        "            total_dic[fl_name] =  reformate_dic(get_info_dic(fl_path))\n",
        "    final_dic = compare_results(total_dic)\n",
        "    sp_list = list(total_dic.keys())\n",
        "    # print(final_dic)\n",
        "    write_dic2_file(final_dic, sp_list, output_name)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    print(\"Well Done!\")"
      ],
      "metadata": {
        "id": "20RPKoO7ihp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pFind_protein_contrast\n",
        "def main():\n",
        "    total_dic = {}\n",
        "    for fl in os.listdir(BASE_PATH):\n",
        "        if fl.endswith(\".protein\"):\n",
        "            fl_path = os.path.join(BASE_PATH, fl)\n",
        "            fl_name = fl[:-8]\n",
        "            total_dic[fl_name] =  reformate_dic(get_info_dic(fl_path))\n",
        "    final_dic = compare_results(total_dic)\n",
        "    sp_list = list(total_dic.keys())\n",
        "    print(final_dic)\n",
        "    write_dic2_file(final_dic, sp_list, output_name)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    print(\"Well Done!\")"
      ],
      "metadata": {
        "id": "NFpnqp1aiXd2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}