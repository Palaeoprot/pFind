{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1ARhgBaYG1B65PeKPHuIit0JtTftdu8LV",
      "authorship_tag": "ABX9TyOr0ro1spMRKkx9iKMGpZ71",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Palaeoprot/pFind/blob/main/FASTA_reader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To parse FASTA files\n",
        "Attempts to understand different headers on FASTA files and read this into a dataframe\n",
        "Then using the 'Genus' to fill in a taxonomic heirarchy\n",
        "It may make errors!"
      ],
      "metadata": {
        "id": "gwxljhr4DFFd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The FASTA file format\n",
        "\n",
        "As we have seen, sequence data is ubiquitous in computational biology and bioinformatics. One of the most straightforward methods of representing that data is as a FASTA file. [FASTA format](https://en.wikipedia.org/wiki/FASTA_format) files are simply text files. They may have various file extensions including .txt, .fa, .fasta, .fna or .faa. Typically, .fna indicates a nucleotide fasta file, whereas .faa indicates an amino acid fasta file. The name FASTA format orginates from the name of an old program, FASTA, that was the first to use this format. But now many different programs in bioinformatics use this format."
      ],
      "metadata": {
        "id": "59pmTZFLggiz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The structure of FASTA files\n",
        "\n",
        "Here's how FASTA files are structured:\n",
        "\n",
        "- FASTA files can contain one or more sequences\n",
        "- Each sequence entry has two main parts, an **identifier line** and one or more **sequence lines**\n",
        "- The **identifier line** *must* begin with a `>` (greater than) character. This line says what the sequence is. The identifier line also indicates that all following lines are sequence, until you reach either another identifier line or the end of the file. In some cases, identifier lines *may* also contain additional information about the sequence - like it's putative function - but this entirely depends on the specific database or research group that wrote the FASTA file.\n",
        "The identifier line is: `>tr|R9WNI0|R9WNI0_HUMAN Fragile X mental retardation 1 OS=Homo sapiens OX=9606 GN=FMR1 PE=1 SV=1`\n",
        "\n",
        "- **Sequence line(s).** the line(s) of a FASTA file after an identifier line, contain the actual sequence data. In some cases, long sequences will simply be placed on a single very long line. In other FASTA files, like this one, long sequences are broken up into multiple lines, each with no more than a certain number of characters (typically 60)."
      ],
      "metadata": {
        "id": "ctPfJ_hEg27c"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc3YuPrGgEJG"
      },
      "source": [
        "In computer science, parsers ) (see e.g. [parsing](https://en.wikipedia.org/wiki/Parsing)) are pieces of code that take  is the process of taking some input and interpreting it in terms of data structures that are useful within your program.\n",
        "\n",
        "Building on our ability to open and print the contents of a FASTA file in python, let's build a FASTA parser step by step. Once we're done, we should have all our sequences properly associated with their names in python, and we should be able to look up each sequence easily by its identifier.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YzDx6vJbzovJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee2de95d-81b0-4922-d8e8-8372efef8434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import auth, drive\n",
        "auth.authenticate_user()\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up"
      ],
      "metadata": {
        "id": "YBWsok3tC-iT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import json\n",
        "from collections import OrderedDict"
      ],
      "metadata": {
        "id": "K9Dx6PCtOgW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global Variables"
      ],
      "metadata": {
        "id": "9C8yKsydi3X2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#STUDY_NAME = 'CatePinkWhtPaste'\n",
        "STUDY_NAME = 'Dinosaur'\n",
        "\n",
        "BASE_PATH = f'/content/drive/MyDrive/Colab_Notebooks/NovorCloud/{STUDY_NAME}'\n",
        "# DENOVO_PATH = f'{BASE_PATH}/{SAMPLE_NAME}.denovo.csv'\n",
        "FOLDER_PREFIX = 'F_2 - '\n",
        "SAMPLE_NAME = '260423_Turkey_Collagen_1hr_1_in_100'\n",
        "#SAMPLE_NAME = '20230614-0314_QEHF3_1005195_ONJ_TR_MatthewEvo_14_LLM_C_PinkP_12_ICib'\n",
        "PSMS_PATH = f'{BASE_PATH}/{FOLDER_PREFIX}{SAMPLE_NAME}/{SAMPLE_NAME}.psm.csv'\n",
        "# PEPS_PATH = f'{BASE_PATH}/{SAMPLE_NAME}.peps.txt'\n",
        "# FASTA_PATH = f'{BASE_PATH}/{SAMPLE_NAME}.proteins.fasta'\n",
        "#COMBINED_FASTA_PATH = f'{BASE_PATH}/{STUDY_NAME}_deduplicated.proteins.fasta'\n",
        "\n",
        "gene_list = [\"COL1A1\", \"COL1A2\", \"COL3A1\"]\n",
        "gene_name = 'COL1A1'"
      ],
      "metadata": {
        "id": "vY0ZoMEvi0i-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ctEXtNVnR6vi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Functions"
      ],
      "metadata": {
        "id": "upyjx6UUC6bA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NovorClouud FASTA\n",
        "def parse_novor_fasta(fasta_file):\n",
        "    with open(fasta_file, 'r') as file:\n",
        "        fasta_data = file.read()\n",
        "\n",
        "    records = fasta_data.strip().split('>')\n",
        "    parsed_data = []\n",
        "\n",
        "    for record in records:\n",
        "        if not record:\n",
        "            continue\n",
        "\n",
        "        lines = record.split('\\n')\n",
        "        header = lines[0]\n",
        "        sequence = ''.join(lines[1:])\n",
        "\n",
        "        # Extract gene\n",
        "        gene = re.search(r'COL1A1\\w*', header, re.IGNORECASE)\n",
        "        gene = gene.group() if gene else 'Unknown'\n",
        "\n",
        "        # Sequence length (excluding specified characters)\n",
        "        seq_length = len(re.sub(r'[^ACDEFGHIKLMNPQRSTVWY]', '', sequence))\n",
        "\n",
        "        # Extract genus and species\n",
        "        match = re.search(r'\\b[A-Z][a-z]*\\b \\b[a-z]+\\b', header)\n",
        "        if match:\n",
        "            genus, species = match.group().split()\n",
        "        else:\n",
        "            genus, species = 'Unknown', 'Unknown'\n",
        "\n",
        "        parsed_data.append([gene, header, sequence, seq_length, genus, species])\n",
        "\n",
        "    return parsed_data\n",
        "\n",
        "#NovorCloud FASTA parsing\n",
        "\n",
        "def parse_novor_fasta(fasta_file):\n",
        "    with open(fasta_file, 'r') as file:\n",
        "        fasta_data = file.read()\n",
        "\n",
        "    records = fasta_data.strip().split('>')\n",
        "    parsed_data = []\n",
        "\n",
        "    for record in records:\n",
        "        if not record:\n",
        "            continue\n",
        "\n",
        "        lines = record.split('\\n')\n",
        "        header = lines[0]\n",
        "        sequence = ''.join(lines[1:])\n",
        "\n",
        "        # Extract gene\n",
        "        gene = re.search(r'COL1A1\\w*', header, re.IGNORECASE)\n",
        "        gene = gene.group() if gene else 'Unknown'\n",
        "\n",
        "        # Sequence length (excluding specified characters)\n",
        "        seq_length = len(re.sub(r'[^ACDEFGHIKLMNPQRSTVWY]', '', sequence))\n",
        "\n",
        "        # Extract genus and species\n",
        "        match = re.search(r'\\b[A-Z][a-z]*\\b \\b[a-z]+\\b', header)\n",
        "        if match:\n",
        "            genus, species = match.group().split()\n",
        "        else:\n",
        "            genus, species = 'Unknown', 'Unknown'\n",
        "\n",
        "        parsed_data.append([gene, header, sequence, seq_length, genus, species])\n",
        "\n",
        "    return parsed_data\n",
        "\n",
        "def clean_gene_name(gene_name):\n",
        "    \"\"\"\n",
        "    Simplify the gene name by removing unwanted characters and possibly\n",
        "    normalizing the format if necessary.\n",
        "\n",
        "    Parameters:\n",
        "    gene_name (str): The full gene name to clean.\n",
        "\n",
        "    Returns:\n",
        "    str: A cleaned-up version of the gene name.\n",
        "    \"\"\"\n",
        "    # Example of simplification, adapt as needed\n",
        "    return re.sub(r'[^a-zA-Z0-9\\s]', '', gene_name).strip()\n",
        "\n",
        "def parse_fasta_header(header):\n",
        "    \"\"\"\n",
        "    Parse the FASTA header to extract sequence ID, cleaned gene name,\n",
        "    species name, and GeneID.\n",
        "\n",
        "    Parameters:\n",
        "    header (str): The FASTA header string.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing sequence ID, cleaned gene name, species name, and GeneID.\n",
        "    \"\"\"\n",
        "    parts = header.split('|')\n",
        "    seq_id = parts[0].strip()\n",
        "    gene_name = clean_gene_name(parts[1].strip())\n",
        "    species_name = re.search(r'\\[(.*?)\\]', header).group(1)\n",
        "    gene_id = re.search(r'#(\\d+)#', header).group(1)\n",
        "\n",
        "    return seq_id, gene_name, species_name, gene_id\n",
        "\n",
        "def process_fasta_files(base_path, study_name):\n",
        "    \"\"\"\n",
        "    Process all FASTA files within the given base path, combining and\n",
        "    deduplicating records based on GeneID.\n",
        "\n",
        "    Parameters:\n",
        "    base_path (str): The base directory containing FASTA files.\n",
        "    study_name (str): The name of the study for output file naming.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    combined_records = OrderedDict()\n",
        "\n",
        "    for root, dirs, files in os.walk(base_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.fasta'):\n",
        "                fasta_path = os.path.join(root, file)\n",
        "                with open(fasta_path, 'r') as fasta_file:\n",
        "                    records = fasta_file.read().strip().split('>')\n",
        "                    for record in records:\n",
        "                        if not record:\n",
        "                            continue\n",
        "                        lines = record.split('\\n')\n",
        "                        header = lines[0]\n",
        "                        sequence = ''.join(lines[1:])\n",
        "                        seq_id, gene_name, species_name, gene_id = parse_fasta_header(header)\n",
        "                        combined_records[gene_id] = (seq_id, gene_name, species_name, sequence)\n",
        "\n",
        "    combined_fasta_path = f'{base_path}/{study_name}_deduplicated.proteins.fasta'\n",
        "    with open(combined_fasta_path, 'w') as output_file:\n",
        "        for gene_id, (seq_id, gene_name, species_name, sequence) in combined_records.items():\n",
        "            output_file.write(f'>{seq_id} {gene_name} [{species_name}] | |#{gene_id}#\\n{sequence}\\n')\n",
        "\n",
        "\n",
        "#More traditional fasta files\n",
        "def parse_NCBI_fasta(input_file):\n",
        "    \"\"\"Return a dict of {id:protein_seq} pairs based on the sequences in the input FASTA file\n",
        "    input_file -- a file handle for an input fasta file\n",
        "    \"\"\"\n",
        "    parsed_seqs = {}\n",
        "    curr_seq_id = None\n",
        "    curr_seq = []\n",
        "\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "\n",
        "        if line.startswith(\">\"):\n",
        "            if curr_seq_id is not None:\n",
        "                parsed_seqs[curr_seq_id] = ''.join(curr_seq)\n",
        "\n",
        "            curr_seq_id = line[1:]\n",
        "            curr_seq = []\n",
        "            continue\n",
        "\n",
        "        curr_seq.append(line)\n",
        "\n",
        "    #Add the final sequence to the dict\n",
        "    parsed_seqs[curr_seq_id] = ''.join(curr_seq)\n",
        "    return parsed_seqs\n",
        "\n",
        "import re\n",
        "\n",
        "def parse_messy_fasta(file_name, gene):\n",
        "    \"\"\"\n",
        "    Parses a FASTA file with potentially messy headers to extract and clean specific data.\n",
        "\n",
        "    This function reads a FASTA file, cleans up each sequence's header to extract relevant biological information,\n",
        "    and filters sequences by a specified gene name. The output is a list of cleaned records, each containing\n",
        "    the gene name, the original header, the sequence, its length, and the extracted biological taxonomy\n",
        "    information (genus and species).\n",
        "\n",
        "    Parameters:\n",
        "    - file_name: str. The path to the FASTA file.\n",
        "    - gene: str. The gene name to filter sequences by.\n",
        "\n",
        "    Returns:\n",
        "    - parsed_records: list of str. Each element is a comma-separated string containing:\n",
        "                      the gene name, original header, cleaned sequence, sequence length,\n",
        "                      gene name extracted from the header (if any), genus, and species.\n",
        "    \"\"\"\n",
        "\n",
        "    records = []\n",
        "    current_header = None\n",
        "    current_seq = ''\n",
        "\n",
        "    with open(file_name) as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "\n",
        "            if line.startswith('>'):\n",
        "                if current_header:\n",
        "                    # Append the record before starting a new one\n",
        "                    records.append((gene, current_header, current_seq, len(current_seq)))\n",
        "                    current_seq = ''\n",
        "                # Remove '>' and start new header\n",
        "                current_header = line[1:]\n",
        "            else:\n",
        "                # Clean and append sequence lines, removing any characters not A-Y\n",
        "                current_seq += re.sub('[^A-Y]', '', line)\n",
        "\n",
        "    # Append the last record\n",
        "    if current_header:\n",
        "        records.append((gene, current_header, current_seq, len(current_seq)))\n",
        "\n",
        "    parsed_records = []\n",
        "    for gene, header, sequence, seq_length in records:\n",
        "        # Attempt to extract genus and species from the header\n",
        "        name_parts = re.search(r'OS=([^ O]+) ([^ O]+)', header)\n",
        "        if not name_parts:\n",
        "            name_parts = re.search(r'\\|[^|]+\\|\\s*([^ ]*)\\s*([^ ]*)', header)\n",
        "\n",
        "        genus = species = str_gene = ''\n",
        "        if name_parts:\n",
        "            genus, species = name_parts.groups()\n",
        "\n",
        "        # Extract gene name if present in the header\n",
        "        str_gene_match = re.search(r'col\\w*', header, re.IGNORECASE)\n",
        "        if str_gene_match:\n",
        "            str_gene = str_gene_match.group(0)\n",
        "\n",
        "        # Prepare and append the cleaned record\n",
        "        parsed_records.append(','.join([gene, header, sequence, str(seq_length), str_gene, genus, species]))\n",
        "\n",
        "    return parsed_records"
      ],
      "metadata": {
        "id": "f9e-48tESPdD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EProcess fasta files\n",
        "\n",
        "process_fasta_files(BASE_PATH, STUDY_NAME)\n",
        "\n"
      ],
      "metadata": {
        "id": "IjMHWgv0z7I0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def parse_fasta (fasta_file):\n",
        "#     with open(fasta_file, 'r') as file:\n",
        "#         fasta_data = file.read()\n",
        "\n",
        "#     records = fasta_data.strip().split('>')\n",
        "#     parsed_data = []\n",
        "\n",
        "#     for record in records:\n",
        "#         if not record:\n",
        "#             continue\n",
        "\n",
        "#         lines = record.split('\\n')\n",
        "#         header = lines[0]\n",
        "#         sequence = ''.join(lines[1:])\n",
        "\n",
        "#         # Extract gene\n",
        "#         gene = re.search(r'COL1A1\\w*', header, re.IGNORECASE)\n",
        "#         gene = gene.group() if gene else 'Unknown'\n",
        "\n",
        "#         # Sequence length (excluding specified characters)\n",
        "#         seq_length = len(re.sub(r'[^ACDEFGHIKLMNPQRSTVWY]', '', sequence))\n",
        "\n",
        "#         # Extract genus and species\n",
        "#         match = re.search(r'\\b[A-Z][a-z]*\\b \\b[a-z]+\\b', header)\n",
        "#         if match:\n",
        "#             genus, species = match.group().split()\n",
        "#         else:\n",
        "#             genus, species = 'Unknown', 'Unknown'\n",
        "\n",
        "#         parsed_data.append([gene, header, sequence, seq_length, genus, species])\n",
        "\n",
        "#     return parsed_data"
      ],
      "metadata": {
        "id": "CcK0VHOyTRQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function: load_dict\n",
        "# Loads a master dictionary from a file.\n",
        "# This function reads a JSON file and returns its contents as a dictionary.\n",
        "#\n",
        "# Parameters:\n",
        "# file_path (str): The file path to the JSON file containing the dictionary.\n",
        "#\n",
        "# Returns:\n",
        "# dict: A dictionary representing the contents of the dictionary file.\n",
        "# ------------------------------------------------------------------------------\n",
        "def load_dict(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        return json.load(file)\n"
      ],
      "metadata": {
        "id": "MaBX4U7ZCu9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_record(header, sequence):\n",
        "    \"\"\"Processes a single record and extracts the desired information.\n",
        "\n",
        "    Args:\n",
        "        header: The header string.\n",
        "        sequence: The amino acid sequence.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the extracted information.\n",
        "    \"\"\"\n",
        "\n",
        "    record = {\n",
        "        \"gene\": \"COL1A1\",  # Always set to COL1A1\n",
        "        \"header\": header,\n",
        "        \"sequence\": sequence,\n",
        "        \"seq_length\": count_aa_length(sequence),\n",
        "    }\n",
        "\n",
        "    # Extract genus and species from header\n",
        "    genus, species = extract_genus_species(header)\n",
        "    record[\"genus\"] = genus\n",
        "    record[\"species\"] = species\n",
        "\n",
        "    # Extract gene name from header (if found)\n",
        "    str_gene = extract_gene_name(header)\n",
        "    record[\"str_gene\"] = str_gene\n",
        "\n",
        "    return record"
      ],
      "metadata": {
        "id": "TyVB3Uk2SllD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_aa_length(sequence):\n",
        "    \"\"\"Counts the length of the amino acid sequence, excluding non-AA characters.\"\"\"\n",
        "    return len(re.sub(r\"[^ACDEFGHIKLMNPQRSTVWY]\", \"\", sequence))\n"
      ],
      "metadata": {
        "id": "ojNjl2RzSqVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_genus_species(header):\n",
        "    \"\"\"Extracts genus and species names from the header using multiple patterns.\"\"\"\n",
        "    patterns = [\n",
        "        r\"^(\\w+)\\_(\\w+)$\",  # Pattern 1: genus_species\n",
        "        r\"OS=(\\w+)\\s(\\w+)\",  # Pattern 2: OS=genus species\n",
        "        r\"\\|(\\w+)\\|(\\w+)\\|\",  # Pattern 3: |genus|species|\n",
        "    ]\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, header)\n",
        "        if match:\n",
        "            return match.groups()\n",
        "\n",
        "    # If no pattern matches, use a placeholder\n",
        "    return \"Unknown\", \"Unknown\""
      ],
      "metadata": {
        "id": "YtyhKbxZSud0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_gene_name(header):\n",
        "    \"\"\"Extracts the gene name from the header (if found).\"\"\"\n",
        "    gene_name_pattern = r\"COL1A1|col1a1b|col1b\"\n",
        "    match = re.search(gene_name_pattern, header, flags=re.IGNORECASE)\n",
        "    return match.group(0) if match else None"
      ],
      "metadata": {
        "id": "HYU0nFpjSw53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P090KuDxeyIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Reading and writing FASTA files\n",
        "\n",
        "This section describes how to read and write biological sequences stored in FASTA files.\n",
        "\n",
        "#### In this section you will learn\n",
        "* How to read and write text files in python\n",
        "* How sequence data are represented in the FASTA file format\n",
        "* How to download data from an online address using `urlretrieve`\n",
        "* How to check if a file is in our current directory using `listdir`\n",
        "* How to work with special tab (`'\\t'`) and newline(`'\\n'`) characters\n",
        "* How to combine `if` statements and `for` loops to read a FASTA file in python\n",
        "* How to use the `continue` keyword to skip one iteration of a `for` loop in python\n",
        "\n",
        "#### Prerequisites for this section\n",
        "* Have Anaconda python installed\n",
        "* Be familiar with how to run python\n",
        "* Be familiar with the Central Dogma of Molecular Biology, and how to represent DNA,RNA, and Protein sequences using python strings.\n",
        "* Use `for` loops to simplify repetitive code\n",
        "* Use `if` statements to let your code handle different conditions\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9sKQxbV8gZL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parsing FASTA\n",
        "Here is a simple function for parsing a FASTA file into a Python dictionary. The dictionary maps short names to corresponding nucleotide strings (with whitespace removed)."
      ],
      "metadata": {
        "id": "_EpbyPNaezzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_fasta(fh):\n",
        "    fa = {}\n",
        "    current_short_name = None\n",
        "    # Part 1: compile list of lines per sequence\n",
        "    for ln in fh:\n",
        "        if ln[0] == '>':\n",
        "            # new name line; remember current sequence's short name\n",
        "            long_name = ln[1:].rstrip()\n",
        "            current_short_name = long_name.split()[0]\n",
        "            fa[current_short_name] = []\n",
        "        else:\n",
        "            # append nucleotides to current sequence\n",
        "            fa[current_short_name].append(ln.rstrip())\n",
        "    # Part 2: join lists into strings\n",
        "    for short_name, nuc_list in fa.items():\n",
        "        # join this sequence's lines into one long string\n",
        "        fa[short_name] = ''.join(nuc_list)\n",
        "    return fa"
      ],
      "metadata": {
        "id": "i3qugAMfe4dD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first part accumulates a list of strings (one per line) for each sequence. The second part joins those lines together so that we end up with one long string per sequence. Why divide it up this way? Mainly to avoid the poor performance of repeatedly concatenating (immutable) Python strings.\n",
        "\n",
        "I'll test it by running it on the simple multi-FASTA file we saw before:"
      ],
      "metadata": {
        "id": "zDeae_5Ue8Cy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from io import StringIO\n",
        "fasta_example = StringIO(\n",
        "'''>sequence1_short_name with optional additional info after whitespace\n",
        "ACATCACCCCATAAACAAATAGGTTTGGTCCTAGCCTTTCTATTAGCTCTTAGTAAGATTACACATGCAA\n",
        "GCATCCCCGTTCCAGTGAGTTCACCCTCTAAATCACCACGATCAAAAGGAACAAGCATCAAGCACGCAGC\n",
        "AATGCAGCTCAAAACGCTTAGCCTAGCCACACCCCCACGGGAAACAGCAGTGAT\n",
        ">sequence2_short_name with optional additional info after whitespace\n",
        "GCCCCAAACCCACTCCACCTTACTACCAGACAACCTTAGCCAAACCATTTACCCAAATAAAGTATAGGCG\n",
        "ATAGAAATTGAAACCTGGCGCAATAGATATAGTACCGCAAGGGAAAGATGAAAAATTATAACCAAGCATA\n",
        "ATATAG''')\n",
        "parsed_fa = parse_fasta(fasta_example)\n",
        "parsed_fa"
      ],
      "metadata": {
        "id": "91pTZuKbfE1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessing a substring in this way is very fast and simple. The downside is that you've stored all of the sequences in memory. If the FASTA files are really big, this takes lots of valuable memory. This may or may not be a good trade.\n",
        "\n",
        "An alternative is to load only the portions of the FASTA files that you need, when you need them. For this to be practical, we have to have a way of \"jumping\" to the specific part of the specific FASTA file that you're intersted in.\n",
        "\n",
        "Fortunately, there is a standard way of indexing a FASTA file, popularized by the faidx tool in SAMtools. When you have such an index, it's easy to calculate exactly where to jump to when you want to extract a specific substring. Here is some Python to create such an index"
      ],
      "metadata": {
        "id": "X_JOxSHsfa8p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5Ohr0Ohefpe"
      },
      "outputs": [],
      "source": [
        "def index_fasta(fh):\n",
        "    index = []\n",
        "    current_short_name = None\n",
        "    current_byte_offset, running_seq_length, running_byte_offset = 0, 0, 0\n",
        "    line_length_including_ws, line_length_excluding_ws = 0, 0\n",
        "    for ln in fh:\n",
        "        ln_stripped = ln.rstrip()\n",
        "        running_byte_offset += len(ln)\n",
        "        if ln[0] == '>':\n",
        "            if current_short_name is not None:\n",
        "                index.append((current_short_name, running_seq_length,\n",
        "                              current_byte_offset, line_length_excluding_ws,\n",
        "                              line_length_including_ws))\n",
        "            long_name = ln_stripped[1:]\n",
        "            current_short_name = long_name.split()[0]\n",
        "            current_byte_offset = running_byte_offset\n",
        "            running_seq_length = 0\n",
        "        else:\n",
        "            line_length_including_ws = max(line_length_including_ws, len(ln))\n",
        "            line_length_excluding_ws = max(line_length_excluding_ws, len(ln_stripped))\n",
        "            running_seq_length += len(ln_stripped)\n",
        "    if current_short_name is not None:\n",
        "        index.append((current_short_name, running_seq_length,\n",
        "                      current_byte_offset, line_length_excluding_ws,\n",
        "                      line_length_including_ws))\n",
        "    return index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GRjHvTLefpf"
      },
      "source": [
        "What do the fields in those two records mean?  Take the first record: `('sequence1_short_name', 194, 69, 70, 71)`.  The fields from left to right are (1) the short name, (2) the length (in nucleotides), (3) the byte offset in the FASTA file of the first nucleotide of the sequence, (4) the maximum number of nucleotides per line, and (5) the maximum number of *bytes* per line, including whitespace.  It's not hard to convince yourself that, if you know all these things, it's not hard to figure out the byte offset of any position in any of the sequences.  (This is what the `get` member of the `FastaIndexed` class defined below does.)\n",
        "\n",
        "A typical way to build a FASTA index like this is to use [SAMtools], specifically the `samtools faidx` command.  This and all the other `samtools` commands are documented in [its manual](http://samtools.sourceforge.net/samtools.shtml).\n",
        "\n",
        "[SAMtools]: http://samtools.sourceforge.net\n",
        "\n",
        "When you use a tool like this to index a FASTA file, a new file containing the index is written with an additional `.fai` extension.  E.g. if the FASTA file is named `hg19.fa`, then running `samtools faidx hg19.fa` will create a new file `hg19.fa.fai` containing the index.\n",
        "\n",
        "The following Python class shows how you might use the FASTA file together with its index to extract arbitrary substrings without loading all of the sequences into memory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1QGZxV3efpf"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "class FastaOOB(Exception):\n",
        "    \"\"\" Out-of-bounds exception for FASTA sequences \"\"\"\n",
        "\n",
        "    def __init__(self, value):\n",
        "        self.value = value\n",
        "\n",
        "    def __str__(self):\n",
        "        return repr(self.value)\n",
        "\n",
        "class FastaIndexed(object):\n",
        "    \"\"\" Encapsulates a set of indexed FASTA files.  Does not load the FASTA\n",
        "        files into memory but still allows the user to extract arbitrary\n",
        "        substrings, with the help of the index. \"\"\"\n",
        "\n",
        "    __removeWs = re.compile(r'\\s+')\n",
        "\n",
        "    def __init__(self, fafns):\n",
        "        self.fafhs = {}\n",
        "        self.faidxs = {}\n",
        "        self.chr2fh = {}\n",
        "        self.offset = {}\n",
        "        self.lens = {}\n",
        "        self.charsPerLine = {}\n",
        "        self.bytesPerLine = {}\n",
        "\n",
        "        for fafn in fafns:\n",
        "            # Open FASTA file\n",
        "            self.fafhs[fafn] = fh = open(fafn, 'r')\n",
        "            # Parse corresponding .fai file\n",
        "            with open(fafn + '.fai') as idxfh:\n",
        "                for ln in idxfh:\n",
        "                    toks = ln.rstrip().split()\n",
        "                    if len(toks) == 0:\n",
        "                        continue\n",
        "                    assert len(toks) == 5\n",
        "                    # Parse and save the index line\n",
        "                    chr, ln, offset, charsPerLine, bytesPerLine = toks\n",
        "                    self.chr2fh[chr] = fh\n",
        "                    self.offset[chr] = int(offset) # 0-based\n",
        "                    self.lens[chr] = int(ln)\n",
        "                    self.charsPerLine[chr] = int(charsPerLine)\n",
        "                    self.bytesPerLine[chr] = int(bytesPerLine)\n",
        "\n",
        "    def __enter__(self):\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, type, value, traceback):\n",
        "        # Close all the open FASTA files\n",
        "        for fafh in self.fafhs.values():\n",
        "            fafh.close()\n",
        "\n",
        "    def has_name(self, refid):\n",
        "        return refid in self.offset\n",
        "\n",
        "    def name_iter(self):\n",
        "        return self.offset.iterkeys()\n",
        "\n",
        "    def length_of_ref(self, refid):\n",
        "        return self.lens[refid]\n",
        "\n",
        "    def get(self, refid, start, ln):\n",
        "        ''' Return the specified substring of the reference. '''\n",
        "        assert refid in self.offset\n",
        "        if start + ln > self.lens[refid]:\n",
        "            raise ReferenceOOB('\"%s\" has length %d; tried to get [%d, %d)' % (refid, self.lens[refid], start, start + ln))\n",
        "        fh, offset, charsPerLine, bytesPerLine = \\\n",
        "            self.chr2fh[refid], self.offset[refid], \\\n",
        "            self.charsPerLine[refid], self.bytesPerLine[refid]\n",
        "        byteOff = offset\n",
        "        byteOff += (start // charsPerLine) * bytesPerLine\n",
        "        into = start % charsPerLine\n",
        "        byteOff += into\n",
        "        fh.seek(byteOff)\n",
        "        left = charsPerLine - into\n",
        "        # Count the number of line breaks interrupting the rest of the\n",
        "        # string we're trying to read\n",
        "        if ln < left:\n",
        "            return fh.read(ln)\n",
        "        else:\n",
        "            nbreaks = 1 + (ln - left) // charsPerLine\n",
        "            res = fh.read(ln + nbreaks * (bytesPerLine - charsPerLine))\n",
        "            res = re.sub(self.__removeWs, '', res)\n",
        "        return res\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Program"
      ],
      "metadata": {
        "id": "wYKafmnxDdGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fastafile path\n",
        "#fasta_file_path = f'/content/drive/MyDrive/Colab_Notebooks/Collagen Sequence/RegExRactorFASTAin/{gene_name}.fasta'\n",
        "fasta_file_path = ('/content/drive/MyDrive/Colab_Notebooks/NovorCloud/Tuuli_Masks/Tuuli_Mask_DA288.proteins.fasta')\n",
        "pparsed_fasta_data = parse_fasta(fasta_file_path)\n",
        "\n",
        "# Creating a DataFrame\n",
        "df = pd.DataFrame(parsed_fasta_data, columns=['gene', 'header', 'sequence', 'length', 'genus', 'species'])\n",
        "\n",
        "genus_dict = load_dict('/content/drive/MyDrive/Colab_Notebooks/Collagen Sequence/TaxonID/Genus_Unified_Dictionary.json')\n",
        "\n",
        "# Fill in other taxonomic levels using the genus dictionary\n",
        "taxonomic_levels = ['phylum', 'class', 'superorder', 'order', 'family']\n",
        "for level in taxonomic_levels:\n",
        "    df[level] = df['genus'].apply(lambda x: genus_dict.get(x, {}).get(level))\n",
        "\n",
        "\n",
        "\n",
        "# # For example, to print the data:\n",
        "# for data in parsed_fasta_data:\n",
        "#     print(data)\n",
        "\n",
        "\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "AOvY-TSbPIJZ",
        "outputId": "49f4b6e2-cee1-48e6-fee9-508a7fed6a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'parsed_fasta_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-7e229f1bbeba>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Creating a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_fasta_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gene'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'header'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sequence'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'genus'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'species'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mgenus_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab_Notebooks/Collagen Sequence/TaxonID/Genus_Unified_Dictionary.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'parsed_fasta_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# records = []\n",
        "# current_header = None\n",
        "# current_seq = ''\n",
        "\n",
        "# with open('sequences.fa') as f:\n",
        "#     for line in f:\n",
        "#         line = line.strip()\n",
        "\n",
        "#         if line.startswith('>'):\n",
        "#             if current_header:\n",
        "#                 records.append((gene, current_header, current_seq, len(current_seq)))\n",
        "#                 current_seq = ''\n",
        "\n",
        "#             current_header = line[1:]\n",
        "#         else:\n",
        "#             current_seq += re.sub('[^A-Y]', '', line)\n",
        "\n",
        "# if current_header:\n",
        "#     records.append((gene, current_header, current_seq, len(current_seq)))\n",
        "\n",
        "# for record in records:\n",
        "#     header = record[1]\n",
        "\n",
        "#     name_parts = re.search(r'OS=([^ O]+) ([^ O]+)', header)\n",
        "#     if not name_parts:\n",
        "#         name_parts = re.search(r'\\|[^|]+\\|\\s*([^ ]*)\\s*([^ ]*)', header)\n",
        "\n",
        "#     genus = species = str_gene = ''\n",
        "#     if name_parts:\n",
        "#         genus, species = name_parts.groups()\n",
        "\n",
        "#     str_gene = re.search(r'col\\w*', header, re.IGNORECASE)\n",
        "#     if str_gene:\n",
        "#         str_gene = str_gene.group(0)\n",
        "\n",
        "#     print(','.join([record[0], header, record[2], str(record[3]), str_gene, genus, species]))"
      ],
      "metadata": {
        "id": "0pgoUfWRL1be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "parsed_fasta_data = parse_fasta(fasta_file_path)\n",
        "\n",
        "# Output the parsed data or convert it to a CSV or DataFrame for further use.\n"
      ],
      "metadata": {
        "id": "PQSiaktdMIKs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}